% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/power_report.R
\name{calculate_power}
\alias{calculate_power}
\title{Obtain hypothesis rejection probabilities}
\usage{
calculate_power(
  graph,
  alpha = 0.05,
  test_groups = list(seq_along(graph$hypotheses)),
  test_types = c("bonferroni"),
  test_corr = NULL,
  sim_n = 100,
  marginal_power = rep(0, length(graph$hypotheses)),
  sim_corr = diag(length(graph$hypotheses)),
  sim_success = 1:2,
  sim_seed = NULL,
  force_closure = FALSE
)
}
\arguments{
\item{graph}{An initial graph as returned by \code{\link[=create_graph]{create_graph()}}}

\item{alpha}{A numeric scalar specifying the global significance level for
testing}

\item{test_groups}{A list of numeric vectors specifying hypotheses to test
together}

\item{test_types}{A character vector of tests to apply to the given groups}

\item{test_corr}{Optional if no \code{test_types} are parametric. A numeric matrix
of correlations between hypotheses' test statistics}

\item{sim_n}{An integer scalar specifying how many simulations to run}

\item{marginal_power}{A numeric vector of mean values to use when simulating
p-values. Exactly one mean per hypothesis is needed, and p-values will be
sampled from the multivariate normal distribution. See Details for more}

\item{sim_corr}{A numeric matrix of correlations between hypotheses used to
sample from the multivariate normal distribution to generate p-values}

\item{sim_success}{A numeric vector indicating which hypotheses can be
rejected to consider an experiment a success (One or more must be rejected,
not necessarily all). It can range from a single hypothesis to all
hypotheses in a graph}

\item{sim_seed}{(Optional) Random seed to set before simulating p-values. Set
this to use a consistent set of p simulations across power calculations}

\item{force_closure}{A logical scalar used to determine whether the full
closure test should be used for Bonferroni testing. Ignored if any tests
are non-Bonferroni}
}
\value{
A list with five elements
\itemize{
\item power_local - rejection proportion for each hypothesis individually
\item power_expected - average number of hypotheses rejected in a single
simulation
\item power_at_least_1 - proportion of simulations which reject any hypothesis
\item power_all - proportion of simulations which reject all hypotheses
\item power_success - proportion of simulations which reject any of the
hypotheses specified in \code{sim_success}
}
}
\description{
It's often difficult to tell how likely a given hypothesis is to be rejected.
This is where power simulations are useful. Under a set of distribution
parameters, many p-values are generated, and the graph is tested against each
one. Any testing strategy can be used. Then probabilities are calculated for
each hypothesis to be rejected, as well as some additional probabilities such
as expected rejections and probability of rejecting any hypothesis
}
\details{
The parameters of the normal distribution are set with \code{marginal_power}
(means) and \code{sim_corr} (correlation between test statistics). The mean of
each hypothesis should be set as its marginal power
\deqn{d_i=P_{\xi_i}(p_i\leq\alpha)} where \eqn{\xi_i} is the non-centrality
parameter. The correlation between test statistics is induced by the study
design.
}
\examples{
par_gate <- simple_successive_1()

# the default is to test all hypotheses with: Bonferroni testing at alpha
# level .05, 0 mean under the alternative, and 0 correlation between
# hypotheses under the alternative
# the default of 100 simulations will usually need to be increased
calculate_power(par_gate, sim_n = 1e5)

# but any test group/type combination that works for [test_graph_closure()]
# can be used
calculate_power(
  par_gate,
  alpha = .025,
  test_groups = list(1:2, 3:4),
  test_types = c("s", "p"),
  test_corr = diag(4),
  sim_n = 1e5,
  sim_success = 1
)

}
\references{
Bretz, F., Maurer, W., Brannath, W., and Posch, M. (2009). A graphical
approach to sequentially rejective multiple test procedures. Statistics in
Medicine, 28(4), 586–604. \url{https://doi.org/10.1002/sim.3495}

Bretz, F., Maurer, W., and Hommel, G. (2011). Test and power considerations
for multiple endpoint analyses using sequentially rejective graphical
procedures. Statistics in Medicine, 30(13), 1489–1501.
\url{https://doi.org/10.1002/sim.3988}

Bretz, F., Posch, M., Glimm, E., Klinglmueller, F., Maurer, W., and Rohmeyer,
K. (2011). Graphical approaches for multiple comparison procedures using
weighted Bonferroni, Simes, or parametric tests. Biometrical Journal, 53(6),
894–913. \url{https://doi.org/10.1002/bimj.201000239}

Lu, K. (2016). Graphical approaches using a Bonferroni mixture of weighted
Simes tests. Statistics in Medicine, 35(22), 4041–4055.
\url{https://doi.org/10.1002/sim.6985}

Xi, D., Glimm, E., Maurer, W., and Bretz, F. (2017). A unified framework for
weighted parametric multiple test procedures. Biometrical Journal, 59(5),
918–931. \url{https://doi.org/10.1002/bimj.201600233}

Xi, D., and Bretz, F. (2019). Symmetric graphs for equally weighted tests,
with application to the Hochberg procedure. Statistics in Medicine, 38(27),
5268–5282. \url{https://doi.org/10.1002/sim.8375}

Rohmeyer K, Klinglmueller F (2020). \emph{gMCP: Graph Based Multiple Test
Procedures}. R package version 0.8-15,
\url{https://cran.r-project.org/package=gMCP}.
}
