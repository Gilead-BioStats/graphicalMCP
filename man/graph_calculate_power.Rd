% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/graph_calculate_power.R
\name{graph_calculate_power}
\alias{graph_calculate_power}
\title{Obtain hypothesis rejection probabilities}
\usage{
graph_calculate_power(
  graph,
  alpha = 0.025,
  test_groups = list(seq_along(graph$hypotheses)),
  test_types = c("bonferroni"),
  test_corr = NULL,
  sim_n = 100,
  marginal_power = rep(alpha, length(graph$hypotheses)),
  sim_corr = diag(length(graph$hypotheses)),
  sim_success = NULL,
  sim_seed = NULL,
  force_closure = FALSE,
  verbose = FALSE
)
}
\arguments{
\item{graph}{An initial graph as returned by \code{\link[=graph_create]{graph_create()}}}

\item{alpha}{A numeric scalar specifying the global significance level for
testing}

\item{test_groups}{A list of numeric vectors specifying hypotheses to test
together}

\item{test_types}{A character vector of tests to apply to the given groups}

\item{test_corr}{Optional if no \code{test_types} are parametric. A numeric matrix
of correlations between hypotheses' test statistics}

\item{sim_n}{An integer scalar specifying how many simulations to run}

\item{marginal_power}{A numeric vector of mean values to use when simulating
p-values. Exactly one mean per hypothesis is needed, and p-values will be
sampled from the multivariate normal distribution. See Details for more}

\item{sim_corr}{A numeric matrix of correlations between hypotheses used to
sample from the multivariate normal distribution to generate p-values}

\item{sim_success}{A list of user-defined functions to apply to the power
results. Functions must take one simulation's logical vector results as an
input, and return a length-one logical vector. For instance, if "success"
means rejecting hypotheses 1 and 2, you would use \code{sim_success = list("1 and 2" = function(x) x[1] && x[2])}. If the list is not named, the function
body will be used as the name. Lambda functions also work, e.g.
\verb{sim_success = list(\\(x) x[3] || x[4])}}

\item{sim_seed}{(Optional) Random seed to set before simulating p-values. Set
this to use a consistent set of p simulations across power calculations}

\item{force_closure}{A logical scalar used to determine whether the full
closure test should be used for Bonferroni testing. Ignored if any tests
are non-Bonferroni}

\item{verbose}{A logical scalar specifying whether the full matrix of
simulations and test results should be included in the output or not}
}
\value{
A list with five elements
\itemize{
\item power_local - rejection proportion for each hypothesis individually
\item power_expected - average number of hypotheses rejected in a single
simulation
\item power_at_least_1 - proportion of simulations which reject any hypothesis
\item power_all - proportion of simulations which reject all hypotheses
\item power_success - proportion of simulations which reject any of the
hypotheses specified in \code{sim_success}
}
}
\description{
It's often difficult to tell how likely a given hypothesis is to be rejected.
This is where power simulations are useful. Under a set of distribution
parameters, many p-values are generated, and the graph is tested against each
one. Any testing strategy can be used. Then probabilities are calculated for
each hypothesis to be rejected, as well as some additional probabilities such
as expected rejections and probability of rejecting any hypothesis
}
\details{
The parameters of the normal distribution are set with \code{marginal_power}
(means) and \code{sim_corr} (correlation between test statistics). The mean of
each hypothesis should be set as its marginal power
\deqn{d_i=P_{\xi_i}(p_i\leq\alpha)} where \eqn{\xi_i} is the non-centrality
parameter. The correlation between test statistics is induced by the study
design.
}
\section{Success}{
 Success will mean something different for each trial, so
there's a lot of flexibility in the \code{sim_success} parameter. However, this
flexibility means there's very little validation of inputs. It's up to the
user to make sure the function(s) passed mean what they think. From an
implementation perspective, each function will be applied row-wise to the
matrix of test results for the simulation, resulting in a \code{sim_n} length
vector. The mean of this vector is returned as "Probability of success"
}

\examples{
par_gate <- simple_successive_1()

# The default is to test all hypotheses with: Bonferroni testing at alpha
# level .025, 0 mean under the alternative, and 0 correlation between
# hypotheses under the alternative
# The default of 100 simulations will usually need to be increased
graph_calculate_power(par_gate, sim_n = 1e5)

# But any test group/type combination that works for [graph_test_closure()]
# can be used
graph_calculate_power(
  par_gate,
  alpha = .025,
  test_groups = list(1:2, 3:4),
  test_types = c("s", "p"),
  test_corr = diag(4),
  sim_n = 1e5,
  sim_success = list(
    function(.) .[1] || .[2],
    function(.) .[1] && .[2]
  )
)

}
\references{
Bretz, F., Maurer, W., Brannath, W., and Posch, M. (2009). A graphical
approach to sequentially rejective multiple test procedures. Statistics in
Medicine, 28(4), 586–604. \url{https://doi.org/10.1002/sim.3495}

Bretz, F., Maurer, W., and Hommel, G. (2011). Test and power considerations
for multiple endpoint analyses using sequentially rejective graphical
procedures. Statistics in Medicine, 30(13), 1489–1501.
\url{https://doi.org/10.1002/sim.3988}

Bretz, F., Posch, M., Glimm, E., Klinglmueller, F., Maurer, W., and Rohmeyer,
K. (2011). Graphical approaches for multiple comparison procedures using
weighted Bonferroni, Simes, or parametric tests. Biometrical Journal, 53(6),
894–913. \url{https://doi.org/10.1002/bimj.201000239}

Lu, K. (2016). Graphical approaches using a Bonferroni mixture of weighted
Simes tests. Statistics in Medicine, 35(22), 4041–4055.
\url{https://doi.org/10.1002/sim.6985}

Xi, D., Glimm, E., Maurer, W., and Bretz, F. (2017). A unified framework for
weighted parametric multiple test procedures. Biometrical Journal, 59(5),
918–931. \url{https://doi.org/10.1002/bimj.201600233}

Xi, D., and Bretz, F. (2019). Symmetric graphs for equally weighted tests,
with application to the Hochberg procedure. Statistics in Medicine, 38(27),
5268–5282. \url{https://doi.org/10.1002/sim.8375}

Rohmeyer K, Klinglmueller F (2020). \emph{gMCP: Graph Based Multiple Test
Procedures}. R package version 0.8-15,
\url{https://cran.r-project.org/package=gMCP}.
}
