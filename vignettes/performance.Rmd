---
title: "Generating the closure tree"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Generating the closure tree}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "##>"
)
```

```{r setup}
library(graphicalMCP)
library(lrstat)
library(gMCP)

library(here)
library(bench)
library(tictoc)
library(ggplot2)
library(forcats)
```

## Introduction

An emphasis of the graphicalMCP package is performance, and one place where improved performance was especially needed was the function to generate weights of all sub-graphs for an MCP graph - `gMCP::generateWeights()` or `graphicalMCP::generate_weights()`. We attempted to create this function using three main strategies, and compared their speed and memory performance with each other, as well as with the gMCP implementation.

## Methodology

The sub-graphs of a graph can be thought of as a tree structure, where each vertex is a sub-graph. The root of the tree is the initial graph, and each successive level of the tree is created by deleting each single node from the graphs in the level above.

### Each-from-initial - `gw_original()`

The first and simplest method of generating sub-graph weights builds on the exported `update_graph()` function, which takes a graph and logical vector (h-vector) as arguments and deletes all the hypotheses from the graph corresponding to the `FALSE` entries in the h-vector. In this case, the whole closure of a graph is generated as `2^n - 1` h-vectors. This can be done efficiently with `expand.grid(rep(list(1:0), n))[-2^n, ]`, where `n` is the number of hypotheses in the graph. Then the initial graph is passed to `update_graph()` along with each h-vector to determine the weights for each sub-graph.

This method is very straightforward, and the steps are clear. However, it is not efficient because each element of the closure starts with the full graph before deleting appropriate hypotheses. This means that for a graph of size 5, hypothesis e.g. `3` gets deleted to get to the `1-2-4-5` graph, and then again to get to the `2-4-5` graph, and so on.

### Parent-child recursive - `generate_weights_recursive()`

Because of the tree structure of the closure of a graph, recursion is a logical candidate for traversing it. In the recursive method, the initial graph is the starting point still. Each hypothesis is deleted from the initial graph, and the recursion is called on each of these smaller graphs as a new starting point. This means that to get to a sub-graph of size 2, it won't start at size 5 and delete 3 hypotheses; it will start at size 3 and delete a single hypothesis. For each level of the recursion, the starting graph & all sub-graphs are returned in a list where each element is a graph. If the graph is an endpoint of the recursion, just the graph is returned.

One of the keys to this method is that, whenever a hypothesis is deleted and the resulting graph passed down the recursion, the corresponding elements of the hypothesis and transition weights are fully removed from the graph structure. This means that previously deleted rows are not unnecessarily included in loops further down into the recursion.

Furthermore, the recursive algorithm has a way to remember what the last hypothesis removed was, and it only creates children by deleting hypotheses larger than the last-deleted node. This avoids the situation of creating level 3+ graphs multiple times by deleting the same nodes but in a different order.

This method is quite fast, but still not the fastest. It is the most memory-efficient.

### Parent-child formula - `generate_weights()`

Using the recursive method created significant gains in speed and memory efficiency, but one other way is even faster. The recursive method generates a list of all sub-graphs, where each graph occurs after its parent. This means that if there's a formulaic way to find a graph's parent given the graph's location in the list, the parent-child location relationship could be calculated rather than generated with recursion.

For the graph ordering generated by `rev(expand.grid(rep(list(1:0), n))[-2^n, ])`, this formula is straightforward. This ordering generates h-vectors that can be thought of as binary numbers counting down from `2^n` to `1`. This means that the bottom half of the h-vectors are identical to the top half, except that the first entry is a 0 instead of a 1. Thus, the parents of the bottom half, elements `2^n / 2 -> 1`, are the elements `2^n -> 2^n / 2 + 1`. And the node to delete to move from an element in the top half to an element in the bottom half is the first. This same logic then applies to the top half and the bottom half individually, ignoring element 1. Each time the set of h-vectors is divided in half, it yields the h-vectors for a graph of size `n - 1` in each half.

Without generating the h-vectors at all, the parent index and node-to-delete index can be calculated directly. The parent index vector is sequential blocks of `1:(2^k)` sequences, and the node-to-delete vector is sequential blocks of `n - k` repeated `k + 1` times, with `0 <= k <= n - 1`. Both vectors have the last element removed, which corresponds to creating the empty sub-graph.

#### Proof idea

Let `g` be a valid MCP graph with `n` hypotheses. We proceed by induction on `n`.

##### Intuition and base cases

Let `n` = 1. Then the closure of `g` is simply the trivial sub-graph, `g`. The parent and delete vectors are empty.

Let `n` = 2. Then the closure of `g` is `(1, 1), (1, 0), (0, 1)`. The parent vector is `(1, 1)`, and the delete vector is `(2, 1)`.

Let `n` = 3. Then the closure of `g` is `(1, 1, 1), (1, 1, 0), (1, 0, 1), (1, 0, 0), (0, 1, 1), (0, 1, 0), (0, 0, 1)`. The parent vector is `(1, 1, 2, 1, 2, 3)`, and the delete vector is `(3, 2, 2, 1, 1, 1)`.

##### Inductive step

Suppose these formulas hold for a graph of size `n - 1`. Then the closure is `2^(n - 1) -> 1` in binary, the parent vector is sequential `1:2^k` sequences, and the delete vector is sequential blocks of `n - 1 - k` repeated `k + 1` times, with `0 <= k <= n - 2`. Add a hypothesis to get to a graph of size `n`. Then the new closure is the `n - 1` closure repeated twice, with a 1 before the first repeat, and a 0 before the second. Thus the difference between a row in the top half and corresponding row in the bottom half is `2^(n - 1)`. And the only difference in elements between such rows is the first element has switched from 1 to 0. Thus, the parent index of a row in the bottom half is the corresponding row in the top half, and the node to delete is the first.

[$\blacksquare$]{style="float:right"}

## Performance

We analyzed performance of the various methods using the bench package.

```{r df-benchmarks-gw}
set.seed(7523)

sizes <- 2:10

list_benchmarks_gw <- lapply(
  sizes,
  function(size) {
    rando <- random_graph(size)
    trn <- rando$transitions
    hyp <- rando$hypotheses
    
    # lrstat::fwgtmat() errors out due to weights not summing to 1, sometimes
    # even when they seem to sum to 1 exactly. This loop tests whether fwgtmat()
    # will run successfully, and updates weights if not
    i <- 0
    res_is_error <- TRUE
    while (res_is_error) {
      cat(size, " | ", i, "\n")

      if (i > 0) {
        hyp[seq_len(size - i)] <- round(hyp[seq_len(size - i)], 6)
        hyp[(size - i + 1):size] <- (1 - sum(hyp[seq_len(size - i)])) / i
      }

      res <- try(fwgtmat(hyp, trn), silent = TRUE)
      res_is_error <- inherits(res, "try-error")
      
      i <- i + 1
    }

    speed_comp <- mark(
      `gMCP (R)` = generateWeights(trn, hyp),
      `graphicalMCP (R)` = generate_weights(rando),
      `lrstat (C++)` = fwgtmat(hyp, trn),
      check = FALSE,
      min_iterations = 5,
      time_unit = "ms"
    )

    speed_comp$size <- size
    speed_comp$mem_alloc <- as.integer(speed_comp$mem_alloc)
    speed_comp$char_expression <- as.character(speed_comp$expression)

    speed_comp
  }
)

df_benchmarks_gw <- do.call(rbind, list_benchmarks_gw)

ggplot(
  df_benchmarks_gw,
  aes(as.factor(size), median,
      colour = fct_reorder2(char_expression, size, median),
      group = char_expression)
) +
  geom_line() +
  geom_point() +
  scale_y_log10() +
  labs(
    title = "Median run time (ms)",
    subtitle = "Generate weights of the closure",
    x = "Number of hypotheses",
    y = NULL,
    colour = "Package"
  )
```

```{r df-benchmarks-seqtest}
set.seed(7523)

sizes <- 2:10

if (file.exists(here("./vignettes/data/df_benchmarks_seqtest.rds"))) {
  df_benchmarks_seqtest <-
    readRDS(here("./vignettes/data/df_benchmarks_seqtest.rds"))
} else {
  list_benchmarks_seqtest <- lapply(
    sizes,
    function(size) {
      rando <- random_graph(size)
      trn <- rando$transitions
      hyp <- rando$hypotheses
  
      p <- as.numeric(
        pnorm(mvtnorm::rmvnorm(1, runif(size, 1.5, 3)), lower.tail = FALSE)
      )
  
      # lrstat::fwgtmat() errors out due to weights not summing to 1, sometimes
      # even when they seem to sum to 1 exactly. This loop tests whether fwgtmat()
      # will run successfully, and updates weights if not
      i <- 0
      res_is_error <- TRUE
      while (res_is_error) {
        cat(size, " | ", i, "\n")
  
        if (i > 0) {
          hyp[seq_len(size - i)] <- round(hyp[seq_len(size - i)], 6)
          hyp[(size - i + 1):size] <- (1 - sum(hyp[seq_len(size - i)])) / i
        }
  
        res <- try(fwgtmat(hyp, trn), silent = TRUE)
        res_is_error <- inherits(res, "try-error")
  
        i <- i + 1
      }
  
      speed_comp <- mark(
        `gMCP shortcut (C)` =
          gMCP(as_gmcp_graph(rando), p, alpha = .025)@rejected,
        `graphicalMCP shortcut (R)` = test_graph_shortcut(rando, p),
        `lrstat Bonferroni (C++)` = fadjpbon(hyp, trn, p) <= .025,
        `gMCP closure parametric (R)` =
          gMCP(as_gmcp_graph(rando), p, alpha = .025, corr = diag(size)),
        `graphicalMCP closure parametric (R)` =
          test_graph_closure(rando, p, corr = diag(size)),
        `lrstat Simes (C++)` =
          fadjpsim(fwgtmat(hyp, trn), p, matrix(1, ncol = size)) <= .025,
        `graphicalMCP closure Simes (R)` =
          test_graph_closure(rando, p, test_types = "s"),
        check = FALSE,
        min_iterations = 5,
        time_unit = "ms"
      )
  
      speed_comp$size <- size
      speed_comp$mem_alloc <- as.integer(speed_comp$mem_alloc)
      speed_comp$char_expression <- as.character(speed_comp$expression)
  
      speed_comp
    }
  )
  
  df_benchmarks_seqtest <- do.call(rbind, list_benchmarks_seqtest)
}
  
ggplot(
  df_benchmarks_seqtest,
  aes(size, median, colour = char_expression, group = char_expression)
) +
  geom_line() +
  geom_point() +
  scale_y_log10() +
  labs(
    title = "Median run time (ms)",
    subtitle = "Test a graph",
    x = "Number of hypotheses",
    y = NULL,
    colour = "Package"
  )
```

```{r df-benchmarks-power}
set.seed(7523)

sizes <- 2:10
sims <- 2^13

if (file.exists(here("./vignettes/data/df_benchmarks_power.rds"))) {
  df_benchmarks_power <-
    readRDS(here("./vignettes/data/df_benchmarks_seqtest.rds"))
} else {
  list_benchmarks_power <- lapply(
    sizes,
    function(size) {
      cat(size, "\n", file = here::here("./vignettes/log.txt"), append = TRUE)
  
      rando <- random_graph(size)
      trn <- rando$transitions
      hyp <- rando$hypotheses
  
      marg_pow <- rep(2.2, size)
      t_corr <- s_corr <- diag(size)
  
      speed_comp <- mark(
        `gMCP shortcut (C)` =
          if (size < 6) calcPower(hyp, .025, trn, marg_pow, s_corr, n.sim = sims),
        `graphicalMCP shortcut (C++)` =
          calculate_power(rando, sim_n = sims, marginal_power = marg_pow,
                          sim_corr = s_corr),
        `gMCP closure parametric (R)` =
          calcPower(hyp, .025, trn, marg_pow, s_corr, t_corr, sims),
        `graphicalMCP closure parametric (R)` =
          calculate_power(rando, sim_n = sims, marginal_power = marg_pow,
                          sim_corr = s_corr, test_types = "parametric",
                          test_corr = t_corr),
        `graphicalMCP closure Simes (R)` =
          calculate_power(rando, sim_n = sims, marginal_power = marg_pow,
                          sim_corr = s_corr, test_types = "simes"),
        check = FALSE,
        min_iterations = 1,
        time_unit = "s"
      )
  
      speed_comp$size <- size
      speed_comp$mem_alloc <- as.integer(speed_comp$mem_alloc)
      speed_comp$char_expression <- as.character(speed_comp$expression)
  
      speed_comp
    }
  )
  
  df_benchmarks_power <- do.call(rbind, list_benchmarks_power)
}

ggplot(
  df_benchmarks_power,
  aes(size, median * 1e5 / sims,
      colour = char_expression,
      group = char_expression)
) +
  geom_line() +
  geom_point() +
  scale_y_log10() +
  labs(
    title = "Median run time (s)",
    subtitle = "Calculate power",
    x = "Number of hypotheses",
    y = NULL,
    colour = "Package"
  )
```



All methods increase in time by `O(2^n)`, but the starting point is lowest for `generate_weights()`.

```{r gg-benchmarks-runtime, fig.width = 7}
gg_benchmarks <- ggplot(df_benchmarks_gw) +
  scale_y_log10() +
  theme_minimal()

gg_benchmarks +
  geom_point(
    aes(
      as.factor(size),
      median,
      colour = fct_reorder2(as.character(expression), size, median)
    )
  ) +
  labs(
    colour = "Expression",
    title = "Log of median runtime in milliseconds",
    x = "Graph size",
    y = NULL
  )
```

Memory also increases at about `O(2^n)`, but here the recursive solution shows a slight advantage.

```{r gg-benchmarks-memory, fig.width = 7}
gg_benchmarks +
  geom_point(
    aes(
      as.factor(size),
      mem_alloc,
      colour = fct_reorder2(as.character(expression), size, median)
    )
  ) +
  labs(
    colour = "Expression",
    title = "Log of bytes used",
    x = "Graph size",
    y = NULL
  )
```

## Performance example

In order to further demonstrate the performance improvement, we will simulate a size 15 graph and generate weights in 2 different ways. Results can be demonstrated to be equivalent, and the time difference will be shown as well. We can see that the performance improvement is significant, especially for larger graphs.

```{r example}
check_methods <- xfun::cache_rds(
  {
    set.seed(1515)

    m <- 15

    w <- sample(1:m, replace = TRUE)
    w <- w / sum(w)

    g <- replicate(m, sample(1:m, replace = TRUE), simplify = TRUE)
    diag(g) <- 0
    g <- g / rowSums(g)

    graph <- new("graphMCP", m = g, weights = w)
    graph2 <- create_graph(w, g)

    tic("gMCP::generateWeights()")
    gmcp_weights <- generateWeights(graph)
    tictoc_gmcp <- toc(quiet = TRUE)$callback_msg

    tic("graphicalMCP::generate_weights()")
    graphicalmcp_weights <- generate_weights(graph2)
    tictoc_graphicalmcp <- toc(quiet = TRUE)$callback_msg

    # Order of results is reversed between packages, and column names differ,
    # but values are the same
    res_equal <- all.equal(
      unname(gmcp_weights[rev(seq_len(nrow(gmcp_weights))), ]),
      unname(graphicalmcp_weights)
    )

    list(tictoc_gmcp, tictoc_graphicalmcp, res_equal)
  },
  clean = FALSE
)
```

```{r ex-results}
cat(check_methods[[1]], "\n")
cat(check_methods[[2]], "\n")
cat(
  "Results from the two packages are equal (up to ordering & names):",
  check_methods[[3]],
  "\n"
)
```
