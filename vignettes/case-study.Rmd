---
title: "Case Study"
output:
  rmarkdown::html_vignette:
    code_folding: "show"
vignette: >
  %\VignetteIndexEntry{Case Study}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(graphicalMCP)
library(tidyr)
```

## Initial graph

This vignette serves to demonstrate testing and power calculations for a moderately complex graph example. We'll follow a hypothetical study for a new diabetes treatment at two dose levels. Each dose level is tested at three endpoints - Mean change in A1C level against placebo as the primary endpoint, and mean time-in-range and retinopathy progression against placebo as the secondary endpoints. Study sample size is 600, with participants spread equally across each dose level and placebo.

The initial weight should be split between the primary hypotheses, and each secondary hypothesis should only be tested if the corresponding primary hypothesis can be rejected. Weight from one dose group should certainly be passed to the other dose group if all of one dose is rejected. But scenarios will be explored where some weight is passed directly between primary hypotheses as well.

These requirements result in the graph below. The value `gamma` can be set to control how much weight is passed between primary hypotheses vs how much is passed to the secondary groups.

```{r initial-graph}
hyp_names <- c("lo_a1c", "lo_tir", "lo_ret", "hi_a1c", "hi_tir", "hi_ret")

complex_gamma <- function(hyp_4, gamma, names = hyp_names) {
  eps <- .0001
  
  hypotheses <- c(hyp_4, 0, 0, 1 - hyp_4, 0, 0)
  transitions <- rbind(
    c(0, (1 - gamma) / 2, (1 - gamma) / 2, gamma, 0, 0),
    c(0, 0, 1, 0, 0, 0),
    c(0, 1 - eps, 0, eps, 0, 0),
    c(gamma, 0, 0, 0, (1 - gamma) / 2, (1 - gamma) / 2),
    c(0, 0, 0, 0, 0, 1),
    c(eps, 0, 0, 0, 1 - eps, 0)
  )

  create_graph(hypotheses, transitions, hyp_names)
}

g_complex <- complex_gamma(.5, .5)

print(g_complex)
```

## Test design {#test-design}

In this section we'll lay out some possible testing strategies. These testing strategies cannot be run until p-values are calculated from study data. See [Test Execution] below

### Bonferroni {#test-design-bonferroni}

The study results could be tested most simply with a Bonferroni testing method.

```{r bonferroni, eval=FALSE}
test_graph(g_complex, calculated_p_values, alpha = .025)
```

### Parametric-Bonferroni {#test-design-parametric-bonferroni}

But we can take advantage of the correlation between doses by testing the primary hypotheses together in a parametric group. Correlation between doses at the same endpoint reduces to 0.5 with equal randomization. For parametric testing, the only correlations that need to be specified are between hypotheses in a parametric group

```{r test-corr}
rho_com_end <- 0.5

t_corr <- rbind(
  c(1, NA, NA, rho_com_end, NA, NA),
  c(NA, 1, NA, NA, rho_com_end, NA),
  c(NA, NA, 1, NA, NA, rho_com_end),
  c(rho_com_end, NA, NA, 1, NA, NA),
  c(NA, rho_com_end, NA, NA, 1, NA),
  c(NA, NA, rho_com_end, NA, NA, 1)
)
```

```{r para-bonf, eval=FALSE}
test_graph(
  g_complex,
  calculated_p_values,
  alpha = .025,
  groups = list(c(1, 4), c(2, 3, 5, 6)),
  test_types = c("p", "b"),
  corr = t_corr
)
```

### Parametric-Simes {#test-design-parametric-simes}

Even beyond that, it may make sense to test each pair of secondary hypotheses as a Simes group. This will add a small amount of power to the secondary hypotheses, which will vary depending on the gamma value.

```{r para-simes, eval=FALSE}
test_graph(
  g_complex,
  calculated_p_values,
  alpha = .025,
  groups = list(c(1, 4), 2:3, 5:6),
  test_types = c("p", "s", "s"),
  corr = t_corr
)
```

These test designs are explored further in [Test execution] below. 

## Power calculations {#power-calculations}

It's not always obvious from an initial graph how easy or difficult it will be to reject each hypothesis. One way to understand this better is to run a power simulation. The essence of a power simulation is to generate many different p-values using an assumed distribution, then test the graph against each set of p-values to see how it performs. In most cases, power will be calculated under many different scenarios to better understand the testing space.

The p-values for a power simulation are sampled from a multivariate normal distribution using a one-sided test. The means of the MVN should be set as the marginal power of each hypothesis, and the correlations should be the correlation between hypotheses that are either known from the study design or assumed.

There are a couple differences between the correlation matrix used in parametric testing (`test_corr`) and the correlation matrix used in power simulations (`sim_corr`). Since the testing correlation is used on clinical data and can improve the chance of finding significant results, the values used should almost always be known, not assumed. If certain correlations are unknown, missing values should be used. However for sampling from the MVN distribution, all correlations must have a value. Any entries which are unknown must be assumed. These assumptions should most likely be tested for sensitivity across different power scenarios. It's also possible that some known correlations will be sensitivity tested to see the impact in the event that they are wrong.

### Parameter space

In order to run a power simulation, several parameters must be set. We'll divide these parameters into two categories: static and dynamic. Static parameters are more likely to be set once for a given study, while dynamic parameters are more variable. 

- Static
  - `alpha` - Significance level
  - `test_groups`/`test_types`/`test_corr` - Testing strategy
  - `sim_n` - Number of simulations to run for power calculations
  - `sim_success` - Definition of success for the trial
- Dynamic
  - `graph` - Design of the hypothesis and transition weights
    - Known before beginning the study, but multiple may be tested for power
  - `marginal_power` - Power to reject each hypothesis at the full alpha level
    - Unknown until study data is collected
  - `sim_corr` - Correlation between hypotheses' test statistics
    - Partially known from study design, but even known values could change after study data is collected

For the study that we're following, here are the static parameters. We also set the random seed, `sim_seed`, for reproducibility.

```{r power, eval=FALSE}
calculate_power(
  graph = <variable graph>,
  alpha = .025,
  test_groups = list(c(1, 4), 2:3, 5:6),
  test_types = c("p", "s", "s"),
  test_corr = t_corr,
  sim_n = 1e5,
  sim_seed = 6923,
  sim_success = c(1, 4),
  marginal_power = <variable power>,
  sim_corr = <variable correlation>
)
```

#### Graph variables

Because of the primary/secondary nature of each dose group, all the initial weight will be on hypotheses 1 & 4. Since hypothesis 4 is the high dose and may be more likely to yield significant results, we may want to skew the weight toward hypothesis 4.

```{r hyp-weights}
v_hyp_4 <- c(0.5, 0.75, 1.0)
```

It's also uncertain what the best choice is for how much weight should be transferred between primary hypotheses. Possible values range in `[0, 1)`.

```{r trn-weights}
v_gamma <- c(0, .5, .99)
```

#### Marginal power

Marginal power is a complicated assumption to test, because there are many possibilities. In a real clinical trial scenario, there may be intuition about where the marginal power will fall, but here we just test a wide variety of scenarios.

```{r marginal-power}
marginal_power_list <- list(
  rep(0, 6),
  rep(1, 6),
  rep(2, 6),
  c(1, 0, 0, 1, 0, 0),
  c(1, 3, 3, 1, 3, 3),
  c(3, 0, 0, 3, 0, 0),
  c(0, 1, 1, 4, 2, 2),
  c(2, 0, 1, 4, 3, 0),
  c(4, 2, 1, 0, 3, 3)
)
```

#### Correlations

We know that with equal sample size between doses, the correlation between corresponding endpoints is 0.5. Correlation between endpoints within a dose is unknown; let's call it `rho_com_dose`. And correlation between different endpoints in different doses can be calculated with the product rule.

```{r sim-corr}
rho_com_end <- 0.5
v_rho_com_dose <- c(0.4, 0.8, .99)

s_corr_list <- lapply(
  v_rho_com_dose,
  function(rho_com_dose) {
    rho_mat <- matrix(rho_com_end * rho_com_dose, 6, 6)
    
    rho_mat[c(1, 4), c(1, 4)] <- rho_com_end
    rho_mat[c(2, 5), c(2, 5)] <- rho_com_end
    rho_mat[c(3, 6), c(3, 6)] <- rho_com_end
    
    rho_mat[1:3, 1:3] <- rho_mat[4:6, 4:6] <- rho_com_dose
    diag(rho_mat) <- 1
    
    rho_mat
  }
)
```

### Power grid

Now bring all the assumptions together and calculate power for each scenario. [Possibly need to pare down the list of scenarios, as the current situation will take ~30 minutes - though maybe this is realistic?]

```{r power-results}
power_scenario <- function(hyp_4, gamma, marginal_power, s_corr) {
  calculate_power(
    graph = complex_gamma(hyp_4, gamma),
    alpha = .025,
    test_groups = list(c(1, 4), 2:3, 5:6),
    test_types = c("p", "s", "s"),
    test_corr = t_corr,
    sim_n = 1e5,
    sim_seed = 6923,
    sim_success = c(1, 4),
    marginal_power = marginal_power,
    sim_corr = s_corr
  )$power
}

res_list <- vector(
  "list",
  length(v_hyp_4) *
    length(v_gamma) *
    length(marginal_power_list) *
    length(s_corr_list)
)
i <- 1

for (hyp_4 in v_hyp_4) {
  for (gamma in v_gamma) {
    for (marginal_power in marginal_power_list) {
      for (s_corr in s_corr_list) {
        
        cat("Calculating power scenario ", i, "\n")
        
        tictoc::tic()
        
        res_list[[i]] <- power_scenario(hyp_4, gamma, marginal_power, s_corr)
        
        i <- i + 1
        
        tictoc::toc()
        
      }
    }
  }
}
```

```{r prettify}
df_hyp_4 <- data.frame(hyp_4 = v_hyp_4)
df_gamma <- data.frame(gamma = v_gamma)

df_marginal_power <- data.frame(do.call(rbind, marginal_power_list))
colnames(df_marginal_power) <- hyp_names

df_rho_com_dose <- data.frame(rho = v_rho_com_dose)

df_params <- expand_grid(df_hyp_4, df_gamma, df_rho_com_dose, df_marginal_power)

df_power <- as.data.frame(do.call(rbind, lapply(res_list, unlist)))

results <- cbind(df_params, df_power)

gt::gt(results)
```

## Study data {#study-data}

```{r study-results}
alpha <- .025

cohort_size <- 200

means <- c(.7, .1, 0, .6, .25, .7)
sds <- c(1, 2, .1, 3, 1, .5)

# simulate performance of each endpoint against placebo
study_results <- mapply(rnorm, rep(cohort_size, 6), means, sds)

t_tests <- apply(study_results, 2, t.test, alternative = "greater")
t_test_means <- lapply(t_tests, getElement, "estimate")
t_test_pvals <- vapply(t_tests, getElement, numeric(1), "p.value")

marginal_power <- vapply(
  t_test_means,
  function(sample_mean) qnorm(alpha, sample_mean, lower.tail = FALSE),
  numeric(1)
)
```

## Test execution {#test-execution}

The study results could be tested most simply with a Bonferroni testing method.

But we can take advantage of the correlation between doses by testing the primary hypotheses together in a parametric group. Correlation between doses at the same endpoint reduces to 0.5 with equal randomization. We can demonstrate more functionality for the package by combining each dose's secondary endpoints together in a Simes group.

~~Correlation between endpoints within a dose group is unknown; we'll assume 0.4. Correlations between one endpoint in one dose group and another endpoint in another dose group can be calculated with the product rule. This results in the correlation matrix below. Testing and power will be calculated at the global level 0.025.~~
