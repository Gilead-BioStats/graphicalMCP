---
title: "Testing basics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Testing basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(graphicalMCP)
library(gMCP)
```

## Testing parameters

Start testing with the example graph from the README, a parallel gate-keeping procedure graph.

```{r create-graph-1}
# A graphical multiple comparison procedure with two primary hypotheses (H1
# and H2) and two secondary hypotheses (H3 and H4)
# See Figure 1 in Bretz, F., Posch, M., Glimm, E., Klinglmueller, F., Maurer,
# W., & Rohmeyer, K. (2011). Graphical approaches for multiple comparison
# procedures using weighted Bonferroni, Simes, or parametric tests. Biometrical
# Journal, 53(6), 894-913.
hypotheses <- c(0.5, 0.5, 0, 0)
transitions <- rbind(
  c(0, 0, 1, 0),
  c(0, 0, 0, 1),
  c(0, 1, 0, 0),
  c(1, 0, 0, 0)
)
names <- c("A1", "A2", "B1", "B2")
par_gate <- create_graph(hypotheses, transitions, names)

pvals <- c(.024, .01, .026, .027)

par_gate
```

This graph can be tested most simply with the default weighted Bonferroni test. When testing at the global alpha level 0.05, we can reject hypotheses A1 and A2, but not B1 or B2.

```{r bonferroni-mix-1}
test_graph(par_gate, p = pvals, alpha = .05)
```

The results of the weighted Simes test are equivalent to weighted Bonferroni in some situations. The power of the Simes test becomes apparent when multiple p-values fall below the global alpha level, but above their local alpha in some intersection(s). In the following case, B1 & B2 are rejected in the Bonferroni testing procedure for intersection `B1 ∩ B2` because the p-value is greater than `α * w` for each hypothesis in that case. However, the Simes test rejects `B1 ∩ B2` because the weight from B1 is added to the weight for B2.

```{r simes-all-1}
test_graph(par_gate, p = pvals, alpha = .05, test_types = "s")
```

If a correlation matrix for the test statistics is partially or fully known, a parametric test can be used for any subsets whose correlation matrix is fully known. Here B1 & B2 get a `c` value calculated that boosts their testing threshold slightly higher. 

```{r parametric-1}
corr1 <- matrix(nrow = 4, ncol = 4)
corr1[3:4, 3:4] <- .5
diag(corr1) <- 1

test_graph(par_gate,
  p = pvals,
  alpha = .05,
  groups = list(1, 2, 3:4),
  test_types = c("b", "b", "p"),
  corr = corr1
)
```

 ~~The parametric test reduces to Bonferroni when there is no correlation between any test statistics.~~ (This doesn't look like it's true, actually)

```{r parametric-2}
corr2 <- diag(4)

test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = diag(4),
  test_types = "p"
)
```

The null case of this is when a parametric group is size 1 (Each correlation matrix is a 1x1 with value 1)

```{r parametric-3}
corr3 <- matrix(nrow = 4, ncol = 4)
diag(corr3) <- 1

test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr3, # Correlation matrix doesn't matter when each group is size 1
  groups = list(1, 2, 3, 4),
  test_types = rep("p", 4)
)
```

Using different test types on different parts of a graph is supported.

```{r mixed-1}
test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr1,
  groups = list(1:2, 3:4),
  test_types = c("s", "p")
)
```

There are two different testing methods - one which tests each hypothesis with the `p <= (c *) w * α` method, and another which calculates adjusted p-values. The adjusted p-values method is much more efficient, so it is the standard method. Additional details about the adjusted p-values calculation can be seen by setting `verbose = TRUE`.

```{r verbose}
test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr1,
  groups = list(1:2, 3:4),
  test_types = c("s", "p"),
  verbose = TRUE
)
```

The critical value method tests every hypothesis in the closure. Setting `critical = TRUE` displays the values used in each of these tests. This can provide more detailed information about what caused a hypothesis to fail than the adjusted p-values. However, it comes at a significant cost in computation time.

```{r critical}
test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr1,
  groups = list(1:2, 3:4),
  test_types = c("s", "p"),
  verbose = TRUE,
  critical = TRUE
)
```

## Performance

`test_graph()` always calculates the full closure, even for Bonferroni testing. If optimal performance is needed, `bonferroni_sequential()` can be used, which uses the sequential testing shortcut. This causes a significant improvement in speed, and either method is faster than `gMCP::gMCP()`. However, using `gMCP::graphTest()` is the fastest option, as it's written primarily in C directly.

```{r benchmark-bonf}
set.seed(3123)
# Randomly generate a graph
m <- 5
w <- sample(1:m, replace = TRUE)
w <- w / sum(w)
g <- replicate(m, sample(1:m, replace = TRUE), simplify = TRUE)
diag(g) <- 0
g <- g / rowSums(g)
graph <- new("graphMCP", m = g, weights = w)
graph2 <- create_graph(w, g)

p <- runif(m, .0001, .05)
sim_corr <- diag(m)

# Bonferroni
bonf_bench <- bench::mark(
  `Bonferroni sequential` =
    bonferroni_sequential(graph2, p)$outputs$rejected,
  `Bonferroni sequential, critical` =
    bonferroni_sequential(graph2, p, critical = TRUE)$outputs$rejected,
  `Bonferroni closure` =
    test_graph(graph2, p)$outputs$rejected,
  `Bonferroni closure, verbose` =
    test_graph(graph2, p, verbose = TRUE)$outputs$rejected,
  `Bonferroni closure, critical` =
    test_graph(graph2, p, critical = TRUE)$outputs$rejected,
  `Bonferroni sequential - graphTest (C)` =
    !!graphTest(p, graph = graph),
  `Bonferroni sequential - gMCP (R)` =
    gMCP(graph, p)@rejected
)

bonf_bench$expression <- as.character(bonf_bench$expression)
gt::gt(bonf_bench[1:7])
```

Simes testing is a bit slower than Bonferroni because the adjusted p-value calculation is more complicated. However, graphicalMCP performance is only 6-7x faster than gMCP for a size 5 graph. This improvement factor grows with the size of the graph.

Somewhat confusingly, `gMCP::graphTest()` allows a test type of "Simes", and it's much faster than the other options shown below. However, this is because it just does Bonferroni sequential testing. In fact, the `test` parameter is not used anywhere, it relies on the presence or absence of a correlation matrix to decide between Bonferroni or parametric testing.

```{r benchmark-simes}
# Simes
simes_bench <- bench::mark(
  `Simes` =
    test_graph(graph2, p, test_types = "s")$outputs$rejected,
  `Simes, verbose` =
    test_graph(graph2, p, test_types = "s", verbose = TRUE)$outputs$rejected,
  `Simes, critical` =
    test_graph(graph2, p, test_types = "s", critical = TRUE)$outputs$rejected,
  # graphTest just does Bonferroni testing without warning in this case
  # !!graphTest(p, graph = graph, test = "Simes"),
  `Simes - gMCP` =
    gMCP(graph, p, test = "Simes")@rejected
)

simes_bench$expression <- as.character(simes_bench$expression)
gt::gt(simes_bench[1:7])
```

Parametric testing is the slowest test, especially when `critical = TRUE`. Parametric testing in graphicalMCP is only 5-6x faster than gMCP for a size 5 graph, because the time is dominated by the multivariate normal calculation. Primary points of improvement in this method would be parallelization in the power simulation, or looking into writing our own version of `pmvnorm()` (Large effort).

```{r benchmark-para}
p_mat <- rbind(p)

para_bench <- bench::mark(
  `Parametric` =
    test_graph(graph2, p, test_types = "p", corr = sim_corr)$outputs$rejected,
  `Parametric, verbose` =
    test_graph(graph2, p, test_types = "p", corr = sim_corr, verbose = TRUE)$outputs$rejected,
  `Parametric, critical` =
    test_graph(graph2, p, test_types = "p", corr = sim_corr, critical = TRUE)$outputs$rejected,
  `Parametric - testGraph` =
    !!graphTest(p_mat, graph = graph, test = "parametric", cr = sim_corr)[1,],
  `Parametric - gMCP` =
    gMCP(graph, p, test = "parametric", correlation = sim_corr)@rejected
)

para_bench$expression <- as.character(para_bench$expression)
gt::gt(para_bench[1:7])
```

## Print options

The print generic for test results includes a couple of additional options. Each section within results is indented 2 spaces by default, but this can be adjusted with `indent`. Numeric values are rounded to 6 decimals to control the amount of space used, but this can be set using the `precision` argument. This only affects the printing format, not the underlying values.

```{r print-indent}
set.seed(3123)
# Randomly generate a graph
m <- 5
w <- sample(1:m, replace = TRUE)
w <- w / sum(w)
g <- replicate(m, sample(1:m, replace = TRUE), simplify = TRUE)
diag(g) <- 0
g <- g / rowSums(g)
graph <- new("graphMCP", m = g, weights = w)
graph2 <- create_graph(w, g)

p <- runif(m, .0001, .05)
sim_corr <- diag(m)

mix_test <- test_graph(
  graph2,
  p = p,
  alpha = .05,
  corr = sim_corr,
  groups = list(1, 2:3, 4:5),
  test_types = c("b", "s", "p"),
  verbose = TRUE,
  critical = TRUE
)

print(mix_test)

print(mix_test, indent = 6, precision = 10)
```
