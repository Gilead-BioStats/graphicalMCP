---
title: "Testing basics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Testing basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(graphicalMCP)
library(gMCP)
library(gt)
message(as.character(Sys.time()))

```

## Testing parameters

Start testing with the example graph from the README, a parallel gate-keeping procedure graph.

```{r create-graph-1}
# A graphical multiple comparison procedure with two primary hypotheses (H1
# and H2) and two secondary hypotheses (H3 and H4)
# See Figure 1 in Bretz, F., Posch, M., Glimm, E., Klinglmueller, F., Maurer,
# W., & Rohmeyer, K. (2011). Graphical approaches for multiple comparison
# procedures using weighted Bonferroni, Simes, or parametric tests. Biometrical
# Journal, 53(6), 894-913.
hypotheses <- c(0.5, 0.5, 0, 0)
transitions <- rbind(
  c(0, 0, 1, 0),
  c(0, 0, 0, 1),
  c(0, 1, 0, 0),
  c(1, 0, 0, 0)
)
names <- c("A1", "A2", "B1", "B2")
par_gate <- create_graph(hypotheses, transitions, names)

pvals <- c(.024, .01, .026, .027)

par_gate
```

This graph can be tested most simply with the default weighted Bonferroni test. When testing at the global alpha level 0.05, we can reject hypotheses A1 and A2, but not B1 or B2.

```{r bonferroni-mix-1}
test_graph(par_gate, p = pvals, alpha = .05)
```

The results of the weighted Simes test are equivalent to weighted Bonferroni in some situations. The power of the Simes test becomes apparent when multiple p-values fall below the global alpha level, but above their local alpha in some intersection(s). In the following case, B1 & B2 are rejected in the Bonferroni testing procedure for intersection `B1 ∩ B2` because the p-value is greater than `α * w` for each hypothesis in that case. However, the Simes test rejects `B1 ∩ B2` because the weight from B1 is added to the weight for B2.

```{r simes-all-1}
test_graph(par_gate, p = pvals, alpha = .05, test_types = "s")
```

If a correlation matrix for the test statistics is partially or fully known, a parametric test can be used for any subsets whose correlation matrix is fully known. Here B1 & B2 get a `c` value calculated that boosts their testing threshold slightly higher. 

```{r parametric-1}
corr1 <- matrix(nrow = 4, ncol = 4)
corr1[3:4, 3:4] <- .5
diag(corr1) <- 1

test_graph(par_gate,
  p = pvals,
  alpha = .05,
  groups = list(1, 2, 3:4),
  test_types = c("b", "b", "p"),
  corr = corr1
)
```

 ~~The parametric test reduces to Bonferroni when there is no correlation between any test statistics.~~ (This doesn't look like it's true, actually)

```{r parametric-2}
corr2 <- diag(4)

test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = diag(4),
  test_types = "p"
)
```

The null case of this is when a parametric group is size 1 (Each correlation matrix is a 1x1 with value 1)

```{r parametric-3}
corr3 <- matrix(nrow = 4, ncol = 4)
diag(corr3) <- 1

test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr3, # Correlation matrix doesn't matter when each group is size 1
  groups = list(1, 2, 3, 4),
  test_types = rep("p", 4)
)
```

Using different test types on different parts of a graph is supported.

```{r mixed-1}
test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr1,
  groups = list(1:2, 3:4),
  test_types = c("s", "p")
)
```

There are two different testing methods - one which tests each hypothesis with the `p <= (c *) w * α` method, and another which calculates adjusted p-values. The adjusted p-values method is much more efficient, so it is the standard method. Additional details about the adjusted p-values calculation can be seen by setting `verbose = TRUE`.

```{r verbose}
test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr1,
  groups = list(1:2, 3:4),
  test_types = c("s", "p"),
  verbose = TRUE
)
```

The critical value method tests every hypothesis in the closure. Setting `critical = TRUE` displays the values used in each of these tests. This can provide more detailed information about what caused a hypothesis to fail than the adjusted p-values. However, it comes at a significant cost in computation time.

```{r critical}
test_graph(
  par_gate,
  p = pvals,
  alpha = .05,
  corr = corr1,
  groups = list(1:2, 3:4),
  test_types = c("s", "p"),
  verbose = TRUE,
  critical = TRUE
)
```

## Performance

`test_graph()` always calculates the full closure, even for Bonferroni testing. If optimal performance is needed, `bonferroni_sequential()` can be used, which uses the sequential testing shortcut. This causes a significant improvement in speed, and either method is faster than `gMCP::gMCP()`. However, using `gMCP::graphTest()` is the fastest option, as it's written primarily in C directly.

The gMCP suite of testing and power functions is a little confusing, so I'm going to document here to remember for future me:

- gMCP() does a lot, and I haven't dug in line by line to all of it. But it's somewhat of a nicer front end for doing different types of tests a single time, not optimized for speed. Though the `useC` parameter may allow for a pretty fast run still?
- Using graphTest() directly is a much faster option, with some drawbacks. **graphTest() has a parameter `test`, which is never used. It uses the presence or absence of a correlation matrix to decide between parametric & Bonferroni testing. It does not do Simes testing.** Bonferroni testing then uses the very fast C-based sequential method. Parametric testing is quite slow, and it's all in R.
- The C code for sequential Bonferroni testing has a couple options - graphproc, which handles a single p-value vector, and graphmult, which handles a matrix of multiple p-value vectors (calling graphproc on each row). They are both made to handle multiple graphs in a list. These two are incredibly fast, and I'd like to learn more about how they can run so fast. Even copying them over and getting them to run with C++ the speed is nowhere close.

I think it would be valuable to build a similar structure, but I'm hoping to have a more organized structure in the end.

- **R-based functions** - To be as fast as possible in R, but without sacrificing transparency. These will be exported, and they're meant to be used sequentially
  - create_graph()
  - update_graph()
  - generate_weights()
  - bonferroni_sequential()
  - test_graph()
    - Possibly separate versions for Simes vs parametric?
- **C++ functions** - To be as fast as possible. Transparency is less important, except to the extent it impacts maintainability. These are all in support of power simulations primarily
  - generate_weights()? Optimizing the testing for Simes & parametric will gain much more speed than re-doing generate_weights() in C++
  - bonferroni_sequential()
  - bonferroni_sequential_power()? May get folded into a general power function eventually
  - test_graph()
    - Still not sure how this will work with parametric testing, or if it will be much faster anyway
  - calculate_power_slow()
    - There's already a pretty fast version for Bonferroni
    - Simes has a huge run time increase, I think because of sorting so many times
    - Parametric is bound to take quite some time, unless we can re-write rmvnorm() to be faster somehow

```{r benchmark-bonf}
# set.seed(3123)
# Randomly generate a graph
m <- 10
w <- sample(1:m, replace = TRUE)
w <- w / sum(w)
g <- replicate(m, sample(1:m, replace = TRUE), simplify = TRUE)
diag(g) <- 0
g <- g / rowSums(g)
graph <- new("graphMCP", m = g, weights = w)
graph2 <- create_graph(w, g)

gw <- generate_weights(graph2)
gwc <- graphicalMCP:::add_critical(graph2, diag(m), .05, list(1:m))

p <- runif(m, .0001, .03)
p1 <- runif(m, .0001, .0005) # Reject all
p2 <- runif(m, .4, .9) # Reject none - These don't seem to matter for speed
sim_corr <- diag(m)

p_ord <- sort(p)
w_ord <- w[order(p)]

h = as.integer(rep(0, m))
a = .05 * w
G = as.double(g)
nH = m

# Bonferroni
bonf_bench <- bench::mark(
  `graphicalMCP, C++ with R wrapper` =
    bs_cpp(graph2, p),
  `gMCP, graphTest (calls C)` =
    graphTest(p, graph = graph),
  `gMCP, raw C` =
    .C("graphproc", h = h, a = a, G = G, p, m, G, 1, 0, 0), # different result?
  check = FALSE
)

message(as.character(Sys.time()))
bonf_bench$expression <- as.character(bonf_bench$expression)
gt(bonf_bench[1:9]) |> 
  tab_header("Bonferroni testing", paste(m, "hypotheses"))
```

Simes testing is a bit slower than Bonferroni because the adjusted p-value calculation is more complicated. However, graphicalMCP performance is only 6-7x faster than gMCP for a size 5 graph. This improvement factor grows with the size of the graph.

Somewhat confusingly, `gMCP::graphTest()` allows a test type of "Simes", and it's much faster than the other options shown below. However, this is because it just does Bonferroni sequential testing. In fact, the `test` parameter is not used anywhere, it relies on the presence or absence of a correlation matrix to decide between Bonferroni or parametric testing. `gMCP::gMCP()` does do Simes testing though.

```{r benchmark-simes}
# Simes
simes_bench <- bench::mark(
  `R test, gw each time` =
    test_graph(graph2, p, test_types = "s")$outputs$rejected,
  `R test, gw once` =
    test_graph_fast(graph2, p, .05, list(1:m), "simes", intersections = gw, graph_size = m, gw_size = 2 ^ m - 1, num_groups = 1),
  `C++ test, gw once` =
    test_graph_fast_simes(graph2, p, .05, list(1:m), "simes", intersections = gw, graph_size = m, gw_size = 2 ^ m - 1, num_groups = 1),
  `C++ test, gw pre, sort once` =
    test_graph_fast_simes_ordered_cpp(graph2, p, .05, list(1:m), "simes", intersections = gw, graph_size = m, gw_size = 2 ^ m - 1, num_groups = 1),
  `R test, gw pre, sort once` =
    test_graph_fast_simes_ordered_r(graph2, p, .05, list(1:m), "simes", intersections = gw, graph_size = m, gw_size = 2 ^ m - 1, num_groups = 1),
  `gMCP::gMCP` =
    gMCP(graph, p, test = "Simes")@rejected
)

message(as.character(Sys.time()))
simes_bench$expression <- as.character(simes_bench$expression)
gt(simes_bench[1:9]) |> 
  tab_header("Simes testing", paste(m, "hypotheses"))
```

Parametric testing is the slowest test, especially when `critical = TRUE`. Parametric testing in graphicalMCP is only 5-6x faster than gMCP for a size 5 graph, because the time is dominated by the multivariate normal calculation. Primary points of improvement in this method would be parallelization in the power simulation, or looking into writing our own version of `pmvnorm()` (Large effort).

```{r benchmark-para}
p_mat <- rbind(p)

para_bench <- bench::mark(
  `gw & adj-p each time` =
    test_graph(graph2, p, test_types = "p", corr = sim_corr)$outputs$rejected,
  `gw pre, adj-p each` =
    test_graph_fast(graph2, p, .05, list(1:m), "parametric", intersections = gw, graph_size = m, gw_size = 2 ^ m - 1, num_groups = 1),
  `gw pre, critical pre` =
    test_graph_fast_parametric(graph2, p, .05, list(1:m), "parametric", intersections = gw, inter_list = gwc, graph_size = m, gw_size = 2 ^ m - 1, num_groups = 1),
  `testGraph` =
    !!graphTest(p_mat, graph = graph, test = "parametric", cr = sim_corr)[1,],
  `gMCP` =
    gMCP(graph, p, test = "parametric", correlation = sim_corr)@rejected
)

message(as.character(Sys.time()))
para_bench$expression <- as.character(para_bench$expression)
gt::gt(para_bench[1:9]) |> 
  tab_header("Parametric testing", paste(m, "hypotheses"))
```

```{r power-bonf}
sims <- 10000

power_bench <- bench::mark(
  `Bonferroni sequential, C++` =
    calculate_power(graph2, sim_n = sims),
  `calcPower` =
    calcPower(graph = graph, alpha = .05, n.sim = sims, corr.sim = diag(m)),
  min_iterations = 3,
  check = FALSE
)

message(as.character(Sys.time()))
power_bench$expression <- as.character(power_bench$expression)
gt::gt(power_bench[1:9]) |> 
  tab_header("Bonferroni power", paste(m, "hypotheses,", sims, "simulations"))
```

```{r power-simes}
power_bench <- bench::mark(
  `R power/test loop, C++ test` =
    run_power4(graph2, sim_n = sims, test_types = "simes"),
  `All R, pre-sort hypotheses` =
    calculate_power(graph2, sim_n = sims, test_types = "simes"),
  min_iterations = 3,
  check = FALSE
)

message(as.character(Sys.time()))
power_bench$expression <- as.character(power_bench$expression)
gt::gt(power_bench[1:9]) |> 
  tab_header("Simes power", paste(m, "hypotheses,", sims, "simulations"))
```

Parametric really only has one viable method at this point, and it's not worth the runtime to compare to gMCP, which takes ages. But here's some code that could compare them.

```{r power-para, eval=FALSE}
# Lower number of sims just to compare methods
power_bench <- bench::mark(
  # `gMCP (n.sim = 1)` =
  #   calcPower(graph = graph, alpha = .05, n.sim = 1, corr.sim = diag(m), corr.test = diag(m)), # n.sim = 10 took > 1 minute to run once
  # `gw & adj-p each time` =
  #   calculate_power_slow(graph2, sim_n = sims, test_types = "parametric", test_corr = diag(m)),
  `calculate_power` =
    calculate_power(graph2, sim_n = sims, test_types = "parametric", test_corr = diag(m)),
  min_iterations = 5,
  check = FALSE
)

message(as.character(Sys.time()))
power_bench$expression <- as.character(power_bench$expression)
gt::gt(power_bench[1:9]) |> 
  tab_header("Parametric power", paste(m, "hypotheses,", sims, "simulations"))
```

```{r power-blend}
# fastest of each test type in graphicalMCP
power_bench <- bench::mark(
  `Bonferroni sequential - C++` = calculate_power(graph2, sim_n = sims),
  `Simes - R, pre-sort` = calculate_power(graph2, sim_n = sims, test_types = "simes"),
  `Parametric - R, pre-calc crit` = calculate_power(graph2, sim_n = sims, test_types = "parametric", test_corr = diag(m)),
  `Para/Simes - R, pre-calc gw only` = calculate_power(graph2, sim_n = sims, test_groups = list(1:2, 3:m), test_types = c("parametric", "simes"), test_corr = diag(m)),
  min_iterations = 3,
  check = FALSE
)

message(as.character(Sys.time()))
power_bench$expression <- as.character(power_bench$expression)
gt::gt(power_bench[1:9]) |> 
  tab_header("All types of power", paste(m, "hypotheses,", sims, "simulations"))
```

## Print options

The print generic for test results includes a couple of additional options. Each section within results is indented 2 spaces by default, but this can be adjusted with `indent`. Numeric values are rounded to 6 decimals to control the amount of space used, but this can be set using the `precision` argument. This only affects the printing format, not the underlying values.

```{r print-indent}
set.seed(3123)
# Randomly generate a graph
m <- 5
w <- sample(1:m, replace = TRUE)
w <- w / sum(w)
g <- replicate(m, sample(1:m, replace = TRUE), simplify = TRUE)
diag(g) <- 0
g <- g / rowSums(g)
graph <- new("graphMCP", m = g, weights = w)
graph2 <- create_graph(w, g)

p <- runif(m, .0001, .05)
sim_corr <- diag(m)

mix_test <- test_graph(
  graph2,
  p = p,
  alpha = .05,
  corr = sim_corr,
  groups = list(1, 2:3, 4:5),
  test_types = c("b", "s", "p"),
  verbose = TRUE,
  critical = TRUE
)

print(mix_test)

print(mix_test, indent = 6, precision = 10)
```
