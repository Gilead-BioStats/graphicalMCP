---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

<!-- badges: start -->
[![CRAN status](https://www.r-pkg.org/badges/version/graphicalMCP)](https://cran.r-project.org/package=graphicalMCP)
[![Codecov test coverage](https://codecov.io/gh/Gilead-BioStats/graphicalMCP/branch/s3-graph_mcp/graph/badge.svg)](https://app.codecov.io/gh/Gilead-BioStats/graphicalMCP?branch=s3-graph_mcp)
[![R-CMD-check](https://github.com/Gilead-BioStats/graphicalMCP/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Gilead-BioStats/graphicalMCP/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

# graphicalMCP <img src="man/figures/logo.png" align="right" height="350" />

## Introduction

A multiple comparison procedure (MCP) is a statistical analysis method that allows for assessing the efficacy of multiple endpoints, some of which are dependent on each other, in a single clinical trial. Endpoints can be different doses, treatment of different conditions, or combined superiority & non-inferiority testing.

In [Bretz et al (2011)](https://onlinelibrary.wiley.com/doi/10.1002/bimj.201000239), a graphical method to MCPs was described, which separates the weighting of the dependency graph from the particular statistical test used to assess each endpoint. This package is a low-dependency implementation of those methods.

## Installation

graphicalMCP is not on CRAN, so install it from GitHub with

```{r eval=FALSE}
# install.packages("pak")
pak::pak("Gilead-BioStats/graphicalMCP")
```

## Basic usage

### Initial graph

The base object in graphicalMCP is an `initial_graph`, which is a weighted, directed graph represented by a matrix of transition (edge) weights, and a vector of hypothesis (vertex) weights.

```{r create-graph}
library(graphicalMCP)

# A graphical multiple comparison procedure with two primary hypotheses (H1
# and H2) and two secondary hypotheses (H3 and H4)
# See Figure 1 in Bretz, F., Posch, M., Glimm, E., Klinglmueller, F., Maurer,
# W., & Rohmeyer, K. (2011). Graphical approaches for multiple comparison
# procedures using weighted Bonferroni, Simes, or parametric tests. Biometrical
# Journal, 53(6), 894-913.
hypotheses <- c(0.5, 0.5, 0, 0)
transitions <- rbind(
  c(0, 0, 1, 0),
  c(0, 0, 0, 1),
  c(0, 1, 0, 0),
  c(1, 0, 0, 0)
)
names <- c("A1", "A2", "B1", "B2")
g_dose <- create_graph(hypotheses, transitions, names)

g_dose
```

### Update graph

Hypotheses can be rejected from the MCP using `update_graph()`. Updated weights and transitions are calculated according to the weighting strategy in [Bretz et al (2011)](https://onlinelibrary.wiley.com/doi/10.1002/bimj.201000239)

```{r update-graph}
update_graph(g_dose, c(TRUE, FALSE, FALSE, TRUE))
```

### Generate weights

The weights of all sub-graphs can be calculated with `generate_weights()`. This uses more efficient code under the hood than `update_graph()` in order to be performant for larger graphs.

```{r generate-weights}
generate_weights(g_dose)
```

### Test hypotheses

A mixture of statistical tests are supported in graphicalMCP. A graph can be tested against a given alpha with `test_graph()`. A report is then generated, showing the graph & test results.

In this example, a weighted Bonferroni test is applied to all hypotheses, with a threshold of 0.05. We can reject a given intersection hypothesis if any of the individual hypotheses within that sub-graph passes the test assigned to it. We can then reject a hypothesis globally if all intersection hypotheses containing that hypothesis are rejected. For instance, in this example we can reject every intersection hypothesis except the one containing only B1 & B2 (Row 3 of `test_results`). Thus, we can reject the null hypotheses for A1 & A2, but we cannot reject the null hypotheses for B1 & B2.

```{r test-graph}
test_graph(
  g_dose,
  p = c(.01, .02, .03, .05),
  alpha = .05,
  test_types = "b",
  groups = list(1:4)
)
```

Simes and parametric testing methods are also supported, using the `test_types` argument. Try setting the `verbose` and `critical` flags for a more detailed report on testing.

```{r test-graph-blend}
test_graph(
  g_dose,
  p = c(.01, .02, .03, .05),
  alpha = .05,
  test_types = c("p", "s"),
  groups = list(1:2, 3:4),
  corr = rbind(
    c(1, .5, NA, NA),
    c(.5, 1, NA, NA),
    c(NA, NA, NA, NA),
    c(NA, NA, NA, NA)
  ),
  verbose = TRUE,
  critical = TRUE
)
```

## Power simulations

It's not always obvious from a given graph structure how easy or difficult it will be to reject each hypothesis. One way to understand this better is to run a power simulation. The essence of a power simulation is to generate many different p-values using some chosen distribution, then test the graph against each set of p-values to see how it performs.

### Bonferroni

```{r power-1}
calculate_power(
  g_dose,
  sim_n = 1e5,
  marginal_power = c(1, 1, 1, 1)
)
```

The `simple_successive_2()` function creates a parallel gate-keeping graph, but some weight is transferred between the primary hypotheses, rather than each passing weight on to its respective secondary hypothesis. This causes the primary hypotheses to be rejected slightly more often, and the secondary hypotheses less often.

```{r power-2}
g_dose_2 <- simple_successive_2(names)

calculate_power(
  g_dose_2,
  sim_n = 1e5,
  marginal_power = c(1, 1, 1, 1)
)
```

### Other tests

Bonferroni testing uses a shortcut to make testing, and therefore power, run very fast (<1s up to a 10-graph/100K-simulation). However, power simulations can be run with any test strategy. Note that other testing strategies will cause a substantial increase in the time a power simulation takes. In rough ascending order of time impact: parametric tests, multiple groups, Simes tests.

```{r power-4}
calculate_power(
  g_dose_2,
  sim_n = 1e5,
  marginal_power = c(1, 1, 1, 1),
  test_types = c("s", "p"),
  test_groups = list(1:2, 3:4),
  test_corr = diag(4)
)
```

## Related work

These methods were originally implemented in R after the 2011 paper in the [gMCP package](https://github.com/kornl/gMCP), which is still available on CRAN today. There is also a lighter version of gMCP implemented in [gMCPmini](https://github.com/allenzhuaz/gMCPmini) and its successor, [gMCPLite](https://github.com/Merck/gMCPLite). These two contain only a subset of the original functionality, but they remove the rJava dependency and add plotting functionality based on ggplot2. 

However, because development has ceased on the original package, we hope to re-implement the methods with a clearer distinction between weighting procedures and test procedures; with fewer dependencies, in particular shedding the Java dependency; with the simpler, more transparent S3 class framework; and with improvements to the accuracy of the parametric and Simes test methods.

A portion of Simes testing is also implemented in the lrstat package (`install.packages("lrstat")`) with similar speed to graphicalMCP.
