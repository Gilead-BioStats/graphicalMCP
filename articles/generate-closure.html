<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="graphicalMCP">
<title>Rationales to generate the closure and the weighting strategy of a graph • graphicalMCP</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Rationales to generate the closure and the weighting strategy of a graph">
<meta property="og:description" content="graphicalMCP">
<meta property="og:image" content="https://urban-sniffle-p11zlpj.pages.github.io/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">graphicalMCP</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/graphicalMCP.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/closed-testing.html">Graphical approaches based on the closure principle</a>
    <a class="dropdown-item" href="../articles/generate-closure.html">Rationales to generate the closure and the weighting strategy of a graph</a>
    <a class="dropdown-item" href="../articles/graph-examples.html">Common multiple comparison procedures illustrated using graphicalMCP</a>
    <a class="dropdown-item" href="../articles/shortuct-testing.html">Sequentially rejective graphical approaches based on Bonferroni tests</a>
    <a class="dropdown-item" href="../articles/validation.html">Validation</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/Gilead-BioStats/graphicalMCP/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Rationales to generate the closure and the weighting strategy of a graph</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/Gilead-BioStats/graphicalMCP/blob/HEAD/vignettes/generate-closure.Rmd" class="external-link"><code>vignettes/generate-closure.Rmd</code></a></small>
      <div class="d-none name"><code>generate-closure.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="motivating-example">Motivating example<a class="anchor" aria-label="anchor" href="#motivating-example"></a>
</h2>
<p>Consider a simple successive graph with four hypotheses. It has two
primary hypotheses <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span> and two secondary hypotheses <span class="math inline">\(H_3\)</span> and <span class="math inline">\(H_4\)</span>. Initially, hypothesis weights are
split equally between <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span> with 0.5. Hypotheses <span class="math inline">\(H_3\)</span> and <span class="math inline">\(H_4\)</span> receive 0 hypothesis weights because
<span class="math inline">\(H_3 (H_4)\)</span> is tested only if <span class="math inline">\(H_1 (H_2)\)</span> is rejected. Thus there is an
edge from <span class="math inline">\(H_1 (H_2)\)</span> to <span class="math inline">\(H_3 (H_4)\)</span> with a transition weight of 1.
When both <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_3\)</span> are rejected, their hypothesis
weights are propagated to <span class="math inline">\(H_2\)</span>;
similarly, when both <span class="math inline">\(H_2\)</span> and <span class="math inline">\(H_4\)</span> are rejected, their hypothesis
weights are propagated to <span class="math inline">\(H_1\)</span>. Thus
there is an edge from <span class="math inline">\(H_3 (H_4)\)</span> to
<span class="math inline">\(H_2 (H_1)\)</span> with a transition weight
of 1. A graphical multiple comparison procedure is illustrated
below.</p>
<p><img src="generate-closure_files/figure-html/base-graph-1-1.png" width="288" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="generating-the-closure">Generating the closure<a class="anchor" aria-label="anchor" href="#generating-the-closure"></a>
</h2>
<p>The closure of this multiple comparison procedure is a collection of
intersection hypotheses <span class="math inline">\(H_1\cap H_2\cap
H_3\cap H_4\)</span>, <span class="math inline">\(H_1\cap H_2\cap
H_3\)</span>, <span class="math inline">\(H_1\cap H_2\cap H_4\)</span>,
<span class="math inline">\(H_1\cap H_3\cap H_4\)</span>, <span class="math inline">\(H_2\cap H_3\cap H_4\ \ldots, H_1, H_2,
H_3\)</span>, and <span class="math inline">\(H_4\)</span>. In other
words, these intersection hypotheses consist of intersections based on
all non-empty subsets of <span class="math inline">\(\{1, 2, 3,
4\}\)</span>, e.g., <span class="math inline">\(\{1, 2, 3\}\)</span>,
<span class="math inline">\(\{1, 2, 4\}\)</span>, <span class="math inline">\(\{1, 3, 4\}\)</span>, <span class="math inline">\(\{2, 3, 4\}\)</span>, <span class="math inline">\(\ldots\)</span>. Thus there are <span class="math inline">\(2^4-1\)</span> intersection hypotheses. An
equivalent way to generate all intersection hypotheses is to use a
binary representation. For example, the intersection hypothesis <span class="math inline">\(H_1\cap H_2\cap H_3\cap H_4\)</span> corresponds
to <span class="math inline">\((1, 1, 1, 1)\)</span> and <span class="math inline">\(H_1\cap H_2\cap H_3\)</span> corresponds to <span class="math inline">\((1, 1, 1, 0)\)</span>. Then the closure can be
indexed by the power set of <span class="math inline">\(\{1, 2, 3,
4\}\)</span> as below. In general, one can use
<code>rev(expand.grid(rep(list(1:0), m)))</code> to general the closure,
where <span class="math inline">\(m\)</span> is the number of
hypotheses.</p>
<pre><code><span><span class="co">#&gt;    H1 H2 H3 H4</span></span>
<span><span class="co">#&gt; 1   1  1  1  1</span></span>
<span><span class="co">#&gt; 2   1  1  1  0</span></span>
<span><span class="co">#&gt; 3   1  1  0  1</span></span>
<span><span class="co">#&gt; 4   1  1  0  0</span></span>
<span><span class="co">#&gt; 5   1  0  1  1</span></span>
<span><span class="co">#&gt; 6   1  0  1  0</span></span>
<span><span class="co">#&gt; 7   1  0  0  1</span></span>
<span><span class="co">#&gt; 8   1  0  0  0</span></span>
<span><span class="co">#&gt; 9   0  1  1  1</span></span>
<span><span class="co">#&gt; 10  0  1  1  0</span></span>
<span><span class="co">#&gt; 11  0  1  0  1</span></span>
<span><span class="co">#&gt; 12  0  1  0  0</span></span>
<span><span class="co">#&gt; 13  0  0  1  1</span></span>
<span><span class="co">#&gt; 14  0  0  1  0</span></span>
<span><span class="co">#&gt; 15  0  0  0  1</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="calculating-the-weighting-strategy">Calculating the weighting strategy<a class="anchor" aria-label="anchor" href="#calculating-the-weighting-strategy"></a>
</h2>
<p>Given the closure, one can calculate the hypothesis weight associated
with every hypothesis in every intersection hypothesis using Algorithm 1
of Bretz et al. (2011). The whole collection of hypothesis weights is
called a weighting strategy. For example, hypothesis weights are <span class="math inline">\((0.5, 0.5, 0, 0)\)</span> for the intersection
hypothesis <span class="math inline">\(H_1\cap H_2 \cap H_3\cap
H_4\)</span>. Then hypothesis weights for the intersection hypothesis
<span class="math inline">\(H_1\cap H_2 \cap H_3\)</span> are <span class="math inline">\((0.5, 0.5, 0, 0)\)</span>, which can be calculated
by removing <span class="math inline">\(H_4\)</span> from the initial
graph and applying Algorithm 1 of Bretz et al. (2011). The algorithm
calculates hypothesis weights in a step-by-step fashion. For example,
for the intersection hypothesis <span class="math inline">\(H_1\cap
H_2\)</span>, it can start from <span class="math inline">\(H_1\cap H_2
\cap H_3\cap H_4\)</span> and calculates hypothesis weights for <span class="math inline">\(H_1\cap H_2 \cap H_3\)</span> by removing <span class="math inline">\(H_4\)</span> and then calculates hypothesis
weights for <span class="math inline">\(H_1\cap H_2\)</span> by removing
<span class="math inline">\(H_3\)</span>; it can also start from <span class="math inline">\(H_1\cap H_2 \cap H_3\)</span> (assuming its
hypotheses weights are stored) and calculates hypothesis weights for
<span class="math inline">\(H_1\cap H_2\)</span> by removing <span class="math inline">\(H_3\)</span>. Therefore, there are two strategies
to calculate the weighting strategy.</p>
<pre><code><span><span class="co">#&gt;      H1   H2   H3   H4</span></span>
<span><span class="co">#&gt; 1  0.50 0.50 0.00 0.00</span></span>
<span><span class="co">#&gt; 2  0.50 0.50 0.00 0.00</span></span>
<span><span class="co">#&gt; 3  0.50 0.50 0.00 0.00</span></span>
<span><span class="co">#&gt; 4  0.50 0.50 0.00 0.00</span></span>
<span><span class="co">#&gt; 5  0.75 0.00 0.00 0.25</span></span>
<span><span class="co">#&gt; 6  1.00 0.00 0.00 0.00</span></span>
<span><span class="co">#&gt; 7  0.75 0.00 0.00 0.25</span></span>
<span><span class="co">#&gt; 8  1.00 0.00 0.00 0.00</span></span>
<span><span class="co">#&gt; 9  0.00 0.75 0.25 0.00</span></span>
<span><span class="co">#&gt; 10 0.00 0.75 0.25 0.00</span></span>
<span><span class="co">#&gt; 11 0.00 1.00 0.00 0.00</span></span>
<span><span class="co">#&gt; 12 0.00 1.00 0.00 0.00</span></span>
<span><span class="co">#&gt; 13 0.00 0.00 0.50 0.50</span></span>
<span><span class="co">#&gt; 14 0.00 0.00 1.00 0.00</span></span>
<span><span class="co">#&gt; 15 0.00 0.00 0.00 1.00</span></span></code></pre>
<div class="section level3">
<h3 id="approach-1-simple-approach">Approach 1: Simple approach<a class="anchor" aria-label="anchor" href="#approach-1-simple-approach"></a>
</h3>
<p>The first strategy utilizes the initial graph as the starting point
and calculates hypothesis weights for all other intersection hypotheses.
For example, to calculate hypothesis weights for <span class="math inline">\(H_1\cap H_2\)</span>, it will start with the
intersection hypothesis <span class="math inline">\(H_1\cap H_2 \cap
H_3\cap H_4\)</span> and sequentially remove <span class="math inline">\(H_4\)</span> and <span class="math inline">\(H_3\)</span> (or in the other order). This
approach is simple to implement since hypothesis weights for <span class="math inline">\(H_1\cap H_2 \cap H_3\cap H_4\)</span> are
determined by the initial graph and always available. This approach is
similar to the one implemented in the gMCP R package. The drawback is
that it does not use other information to reduce the number of
calculations. For example, it is possible that hypothesis weights for
<span class="math inline">\(H_1\cap H_2 \cap H_3\)</span> have been
calculated when calculating for <span class="math inline">\(H_1\cap
H_2\)</span>. Using the information from <span class="math inline">\(H_1\cap H_2 \cap H_3\)</span> would only need the
one-step calculation, compared to the two-step calculation using <span class="math inline">\(H_1\cap H_2 \cap H_3\cap H_4\)</span>.</p>
</div>
<div class="section level3">
<h3 id="approach-2-parent-child-approach">Approach 2: Parent-child approach<a class="anchor" aria-label="anchor" href="#approach-2-parent-child-approach"></a>
</h3>
<p>This approach tries to avoid the drawback of Approach 1 by saving
intermediate graphs. Then it only performs one-step calculation which
could save time. In general, an intersection hypothesis has a parent
intersection hypothesis, which involves all hypotheses involved in the
first intersection and has one extra hypothesis. For example, the second
row of <code>matrix_intersections</code> is <span class="math inline">\(H_1\cap H_2 \cap H_3\)</span> and its parent
intersection is <span class="math inline">\(H_1\cap H_2 \cap H_3\cap
H_4\)</span> in the first row; the third row of
<code>matrix_intersections</code> is <span class="math inline">\(H_1\cap
H_2 \cap H_4\)</span> and its parent intersection is <span class="math inline">\(H_1\cap H_2 \cap H_3\cap H_4\)</span> in the first
row. Thus we can identify the parent intersection hypothesis for each
row in <code>matrix_intersections</code> (except row 1) as the row
number 1, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7. Given this sequence of
parent hypotheses, it is simple to obtain hypothesis weights for an
intersection hypothesis based on its parent intersection hypothesis via
one-step calculation.</p>
<p>It is of interest to understand this pattern and obtain it
efficiently. First, between the bottom half (rows 9 - 15) and top half
(rows 1 - 7), each row’s parent in the bottom half is the corresponding
row in the top half, eight rows up, because the only difference is the
flipping of <span class="math inline">\(H_1\)</span> from 1 in the top
half to 0 in the bottom half. For example, row 15’s parent is in row 15
- 8 = 7. Using this observation, we can determine parent hypotheses for
rows from 9 to 15 as 1, 2, 3, 4, 5, 6, 7. A similar pattern can be
observed for rows from 5 to 8. Their parent hypotheses are in rows 1, 2,
3, 4, respectively, by flipping <span class="math inline">\(H_2\)</span>
from 1 to 0. For rows 3 - 4, their parent hypotheses are in rows 1, 2,
respectively, by flipping <span class="math inline">\(H_3\)</span> from
1 to 0. Lastly for row 2, its parent hypothesis is in row 1. The row
number of the parent hypothesis can be efficiently generated by running
<code>do.call(c, lapply(2^(seq_len(m) - 1), seq_len))[-2^m, ]</code>,
where <span class="math inline">\(m\)</span> is the number of
hypotheses.</p>
</div>
</div>
<div class="section level2">
<h2 id="comparing-different-approaches-to-calculating-weighting-strategies">Comparing different approaches to calculating weighting
strategies<a class="anchor" aria-label="anchor" href="#comparing-different-approaches-to-calculating-weighting-strategies"></a>
</h2>
<p>To benchmark against existing approaches to calculating weighting
strategies, we compare the following approaches:
<code>generateWeights::gMCP</code>, <code>fwgtmat::lrstat</code>,
Approach 1 (graphicalMCP simple) and Approach 2 (graphicalMCP
parent-child). Random graphs are generated for the numbers of hypotheses
of 4, 8, 12, and 16. Computing time (in median log-10 milliseconds) is
plotted below. We can see that <code>generateWeights::gMCP</code> is the
slowest and <code>fwgtmat::lrstat</code> is the fastest. Approach 2
(graphicalMCP parent-child) is faster than Approach 1 (graphicalMCP
simple). Note that <code>fwgtmat::lrstat</code> implements the
calculation using C++, which is known to be faster than R. But it is
less stable than other approaches, e.g., giving errors more often than
others. Given that the computing time of R-based approaches is
acceptable, adding Rcpp dependency is not considered in
<code>graphicalMCP</code>. For these considerations, we implement
Approach 2 in <code>weighting_strategy::graphicalMCP</code>.</p>
<pre><code><span><span class="co">#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Please use `linewidth` instead.</span></span>
<span><span class="co">#&gt; <span style="color: #555555;">This warning is displayed once every 8 hours.</span></span></span>
<span><span class="co">#&gt; <span style="color: #555555;">Call `lifecycle::last_lifecycle_warnings()` to see where this warning was</span></span></span>
<span><span class="co">#&gt; <span style="color: #555555;">generated.</span></span></span></code></pre>
<p><img src="generate-closure_files/figure-html/plot-gw-benchmarks-1.png" width="768" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="improving-power-simulations-using-parent-child-relationships">Improving power simulations using parent-child relationships<a class="anchor" aria-label="anchor" href="#improving-power-simulations-using-parent-child-relationships"></a>
</h2>
<div class="section level3">
<h3 id="conventional-approach-for-power-simulations">Conventional approach for power simulations<a class="anchor" aria-label="anchor" href="#conventional-approach-for-power-simulations"></a>
</h3>
<p>The conventional approach for power simulations is to repeat the
following process many times, e.g., 100,000 times. 1. Simulate a set of
p-values 2. Run the graphical multiple comparison procedure to +
Determine which hypothesis can be rejected + Remove the rejected
hypothesis and update the graph + Repeat until no more hypotheses can be
rejected Note that the same step to update the graph may repeat in many
replications, which may be repetitive. For <span class="math inline">\(m\)</span> hypotheses, there are at most <span class="math inline">\(2^m-1\)</span> graphs depending on which
hypotheses are rejected. These graphs corresponds to the closure and the
weighting strategy. Thus an idea to avoid redundant updating of graphs
is to utilize the weighting strategy.</p>
</div>
<div class="section level3">
<h3 id="power-simulations-using-parent-child-relationships">Power simulations using parent-child relationships<a class="anchor" aria-label="anchor" href="#power-simulations-using-parent-child-relationships"></a>
</h3>
<p>The key to allow this approach is to efficiently identify the row of
the weighting strategy, given which hypotheses are rejected. Remembering
the pattern we found for Approach 2, the bottom half (rows 9 - 15) of
<code>matrix_intersections</code> is the same as the top half (rows 1 -
7), except flipping <span class="math inline">\(H_1\)</span> from 1 to
0. This means that if <span class="math inline">\(H_1\)</span> has not
been rejected (1 for <span class="math inline">\(H_1\)</span> in
<code>matrix_intersections</code>), the row number of that index should
be in the top half. For example, assume that <span class="math inline">\(H_2\)</span> and <span class="math inline">\(H_4\)</span> have been rejected and the index in
<code>matrix_intersections</code> should be <span class="math inline">\((1, 0, 1, 0)\)</span>. Since <span class="math inline">\(H_1\)</span> is 1, the corresponding row should be
in the top half (rows 1- 7). But <span class="math inline">\(H_2\)</span> is 0 and thus the corresponding row
should be in the bottom half within the top half (rows 5 - 7). Since
<span class="math inline">\(H_3\)</span> is 1 and thus the corresponding
row should be in the top half (rows 5 - 6). But <span class="math inline">\(H_4\)</span> is 0 and thus the corresponding row
should be 6. A useful way to calculate the row number for an index of
XXXX is <code>2^m - sum(XXXX * 2^(m:1 - 1))</code>. For example for
XXXX=1010, its row number should be
<code>(1 - 1) * 8 + (1 - 0) * 4 + (1 - 1) * 2 + (1 - 0) * 1 + 1 = 16 - 10 = 6</code>.</p>
<p>With the above way of efficiently identifying rows of
<code>weighting_strategy</code>, power simulations could be implemented
as follows: 1. Obtain the weighting strategy (once for all simulations)
2. Simulate a set of p-values 3. Run the graphical multiple comparison
procedure to + Determine which hypothesis can be rejected + Remove the
rejected hypothesis and identify the row of the weighting strategy +
Repeat until no more hypotheses can be rejected The small modification
in Step 3b make this approach much faster than the conventional approach
for power simulations.</p>
</div>
</div>
<div class="section level2">
<h2 id="comparing-different-approaches-to-power-simulations">Comparing different approaches to power simulations<a class="anchor" aria-label="anchor" href="#comparing-different-approaches-to-power-simulations"></a>
</h2>
<p>To benchmark against existing approaches to calculating weighting
strategies, we compare the following approaches: [gMCP::calcPower()],
Approach 1 (graphicalMCP conventional), and Approach 2 (graphicalMCP
parent-child). Both Holm and fixed sequence procedures are considered
with the numbers of hypotheses of 4, 8, 12, and 16. Computing time (in
median log-10 seconds) is plotted below. We can see that
[gMCP::calcPower()] is the fastest and Approach 1 (graphicalMCP
conventional) is the lowest. Note that [gMCP::calcPower()] implements
the simulation using C, which is known to be faster than R but is not
easy to extend to other situations. Given that the computing time of
Approach 2 (graphicalMCP parent-child) is acceptable, we implement it in
[graphicalMCP::graph_calculate_power].</p>
<p><img src="img/power-benchmarks-plot.png"></p>
<!-- ################################################################################ -->
<!-- The closure of a graph is the set of all sub-graphs, along with their weights calculated according to algorithm 1 of Bretz et al (2011). It is primarily used for [closed testing](link%20to%20closed%20test%20vignette), where all sub-graphs are tested for significance, and results are aggregated to determine which null hypotheses are significant globally. -->
<!-- Throughout this article a common example will be used for demonstrations - the simple successive graph. It has two primary hypotheses, $H_1$ and $H_2$, which have the initial weight evenly split between them. The secondary hypotheses, $H_3$ and $H_4$, only have weight propagated to them if $H_1$ or $H_2$ is deleted, respectively. -->
<!-- ```{r base-graph, fig.dim=c(4, 4)} -->
<!-- ss_graph <- simple_successive_2() -->
<!-- plot(ss_graph, layout = "grid") -->
<!-- ``` -->
<!-- ### Components of the closure -->
<!-- In graphicalMCP, the closure is represented by a matrix, where each row represents a sub-graph (also called an intersection hypothesis), and each column corresponds to an individual hypothesis. This matrix can be created with `graph_generate_weights()`, and it has two parts: An indicator matrix showing which hypotheses are contained in each sub-graph (The so-called powerset of a set), and a weights matrix containing the induced weights of each sub-graph. -->
<!-- ```{r closure-parts} -->
<!-- weighting_strategy <- graph_generate_weights(ss_graph) -->
<!-- matrix_intersections <- weighting_strategy[, seq_along(ss_graph$hypotheses)] -->
<!-- data.frame(Intersection = seq_len(nrow(weighting_strategy))) |> -->
<!--   cbind(weighting_strategy) |> -->
<!--   data.frame() |> -->
<!--   gt() |> -->
<!--   tab_header("Closure of the simple successive graph") |> -->
<!--   tab_spanner("Powerset", H1:H4) |> -->
<!--   tab_spanner("Weights", H1.1:H4.1) |> -->
<!--   tab_style( -->
<!--     cell_text(align = "center", style = "italic"), -->
<!--     cells_body(Intersection) -->
<!--   ) |> -->
<!--   cols_label( -->
<!--     H1.1 = "H1", -->
<!--     H2.1 = "H2", -->
<!--     H3.1 = "H3", -->
<!--     H4.1 = "H4" -->
<!--   ) |> -->
<!--   opt_row_striping() -->
<!-- ``` -->
<!-- ### Properties of the closure -->
<!-- The rows of the closure are generated in a particular way in order to give them some useful properties. -->
<!-- #### Repeating recursive blocks -->
<!-- First, notice how each row can be obtained from some row higher up in the matrix by flipping a single 1 to be a 0. For example, go from row 1 to row 3 by flipping $H_3$, or go from row 10 to row 14 by flipping $H_2$. The upper row in a pairing like this can be thought of as the "parent" sub-graph, and the lower row as the "child" sub-graph. Flipping a 0 to be a 1 and moving up the matrix will be called "finding a sub-graph's parent." Now consider the parent-finding strategy where the left-most 0 in each row is flipped. This reveals a pattern between the bottom half and top half, where each row's parent in the bottom half is the corresponding row in the top half, eight rows up. -->
<!-- ```{r big-pattern} -->
<!-- data.frame(Intersection = seq_len(nrow(weighting_strategy))) |> -->
<!--   cbind(matrix_intersections) |> -->
<!--   data.frame() |> -->
<!--   gt() |> -->
<!--   tab_header("The boxes contain identical matrices") |> -->
<!--   tab_style( -->
<!--     cell_text(align = "center", style = "italic"), -->
<!--     cells_body(Intersection) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("left", "#a069c4", weight = px(2)), -->
<!--     cells_body(H2, c(1:7, 9:15)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("top", "#a069c4", weight = px(2)), -->
<!--     cells_body(H2:H4, c(1, 9)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("right", "#a069c4", weight = px(2)), -->
<!--     cells_body(H4, c(1:7, 9:15)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("bottom", "#a069c4", weight = px(2)), -->
<!--     cells_body(H2:H4, c(7, 15)) -->
<!--   ) -->
<!-- ``` -->
<!-- The pattern then repeats within each box recursively, with the top half of each box matching the bottom half, if the first missing hypothesis is flipped from 0 to 1. -->
<!-- ```{r small-pattern} -->
<!-- data.frame(Intersection = seq_len(nrow(weighting_strategy))) |> -->
<!--   cbind(matrix_intersections) |> -->
<!--   data.frame() |> -->
<!--   gt() |> -->
<!--   tab_header("The boxes contain identical matrices") |> -->
<!--   tab_style( -->
<!--     cell_text(align = "center", style = "italic"), -->
<!--     cells_body(Intersection) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("left", "#a069c4", weight = px(2)), -->
<!--     cells_body(H2, c(1:7, 9:15)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("top", "#a069c4", weight = px(2)), -->
<!--     cells_body(H2:H4, c(1, 9)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("right", "#a069c4", weight = px(2)), -->
<!--     cells_body(H4, c(1:7, 9:15)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("bottom", "#a069c4", weight = px(2)), -->
<!--     cells_body(H2:H4, c(7, 15)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("left", "black", weight = px(2)), -->
<!--     cells_body(H3, c(1:3, 5:7, 9:11, 13:15)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("top", "black", weight = px(2)), -->
<!--     cells_body(H3:H4, c(1, 5, 9, 13)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("right", "black", weight = px(2)), -->
<!--     cells_body(H4, c(1:3, 5:7, 9:11, 13:15)) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_borders("bottom", "black", weight = px(2)), -->
<!--     cells_body(H3:H4, c(3, 7, 11, 15)) -->
<!--   ) -->
<!-- ``` -->
<!-- #### Binary counting {#binary-counting} -->
<!-- The second useful property is somewhat a re-framing of the first, or perhaps could be viewed as a reason why the first is true. Starting with the bottom row, the powerset in this particular order counts up from 1 in binary, incrementing by 1 per row. This means that a row number can be directly calculated from a vector showing which hypotheses are currently deleted from the graph: `row_number == number_of_rows - incl_excl_vec_converted_to_base_10 + 1`. For example, intersection number 6 has hypothesis vector `1010`. When interpreted as binary, this is `1 * 8 + 0 * 4 + 1 * 2 + 0 * 1 = 10` in base 10, and `6 == 15 - 10 + 1`. -->
<!-- ```{r closure-repeat} -->
<!-- data.frame(Intersection = seq_len(nrow(weighting_strategy))) |> -->
<!--   cbind(matrix_intersections) |> -->
<!--   data.frame() |> -->
<!--   gt() |> -->
<!--   tab_header("Binary counting") |> -->
<!--   tab_style( -->
<!--     cell_text(align = "center", style = "italic"), -->
<!--     cells_body(Intersection) -->
<!--   ) |> -->
<!--   tab_style(cell_borders("left", "#a069c4"), cells_body(1, 6)) |> -->
<!--   tab_style(cell_borders("top", "#a069c4"), cells_body(1:5, 6)) |> -->
<!--   tab_style(cell_borders("right", "#a069c4"), cells_body(5, 6)) |> -->
<!--   tab_style(cell_borders("bottom", "#a069c4"), cells_body(1:5, 6)) |> -->
<!--   opt_row_striping() -->
<!-- ``` -->
<!-- ## Strategies -->
<!-- Because the size of the closure grows quickly as graph size increases (An n-graph has `2^n - 1` sub-graphs), calculating the full closure for large graphs can be computationally intensive. Optimizing this process led to three main strategies: -->
<!-- -   The simplest approach, which uses the full graph as the starting point for every sub-graph, then deletes the appropriate hypotheses -->
<!-- -   A recursive method, which traverses the closure tree, deleting one hypothesis each time to step between graphs -->
<!-- -   A formulaic shortcut using the order of graphs generated with the recursive method -->
<!-- Note that the discussion of these methods focuses primarily on the weights side rather than the powerset side of the closure. This is because the fastest methods discovered generate the powerset implicitly from missing values in the weights side. For methods such as the simple approach, which rely on having the powerset in order to generate weights, the powerset can be created efficiently. Here `num_hyps` refers to the number of hypotheses in the initial graph. -->
<!-- ```{r powerset, eval=FALSE, echo=TRUE} -->
<!-- powerset <- as.matrix(rev(expand.grid(rep(list(1:0), num_hyps))[-2^num_hyps, ])) -->
<!-- ``` -->
<!-- ### Simple approach -->
<!-- The simplest approach to generate the weights of the closure is to apply `graph_update()` to the initial graph once for each sub-graph. This is short and sweet to write, but it's inefficient because each hypothesis gets deleted from the graph multiple times. Here is the code for the simple method. -->
<!-- ```{r ggw-simple, echo=TRUE} -->
<!-- ggw_simple <- function(graph) { -->
<!--   num_hyps <- length(graph$hypotheses) -->
<!--   matrix_intersections <- -->
<!--     as.matrix(rev(expand.grid(rep(list(1:0), num_hyps))[-2^num_hyps, ])) -->
<!--   colnames(matrix_intersections) <- names(graph$hypotheses) -->
<!--   matrix_weights <- apply( -->
<!--     matrix_intersections, -->
<!--     1, -->
<!--     function(h) graph_update(graph, !h)$updated_graph$hypotheses, -->
<!--     simplify = FALSE -->
<!--   ) -->
<!--   cbind(matrix_intersections, do.call(rbind, matrix_weights)) -->
<!-- } -->
<!-- ``` -->
<!-- ### Recursive -->
<!-- The recursive method treats the space of sub-graphs as a tree, with the initial graph at the root, and other sub-graphs decreasing in size going down the branches. The essence of the recursive step is to delete a hypothesis in the current graph. But doing this for every hypothesis in every sub-graph in the tree would result in taking multiple paths to many of the graphs. So a key part of the recursive step is that it has memory - Each graph in the tree will only delete the hypotheses that come after the hypothesis that was just deleted to reach the current graph. The base case also needs memory - It is reached when a graph has only one hypothesis left, or when the last-deleted hypothesis number is larger than all current hypotheses. This memory in the recursion enables the tree traversal to reach each unique graph state exactly once. Here is an implementation of the recursion, followed by a wrapper for processing the sub-graph list into the standard matrix form. -->
<!-- ```{r recursion, echo=TRUE} -->
<!-- delete_nodes_recursive <- function(graph, last = 0) { -->
<!--   init_hypotheses <- hypotheses <- graph$hypotheses -->
<!--   init_transitions <- transitions <- graph$transitions -->
<!--   ### base case -->
<!--   int_hyp <- as.integer(names(hypotheses)) -->
<!--   is_single_node <- length(hypotheses) == 1 -->
<!--   last_is_bigger <- last > max(int_hyp) -->
<!--   if (is_single_node || last_is_bigger) { -->
<!--     return(list(graph)) -->
<!--   } -->
<!--   ### recursive step -->
<!--   children <- list() -->
<!--   for (orig_hyp_num in int_hyp[int_hyp > last]) { -->
<!--     del_index <- match(orig_hyp_num, int_hyp) -->
<!--     hyp_nums <- seq_along(hypotheses)[seq_along(hypotheses) != del_index] -->
<!--     for (hyp_num in hyp_nums) { -->
<!--       hypotheses[[hyp_num]] <- -->
<!--         init_hypotheses[[hyp_num]] + -->
<!--         init_hypotheses[[del_index]] * init_transitions[[del_index, hyp_num]] -->
<!--       denominator <- 1 - init_transitions[[hyp_num, del_index]] * -->
<!--         init_transitions[[del_index, hyp_num]] -->
<!--       for (end_num in hyp_nums) { -->
<!--         if (hyp_num == end_num || denominator <= 0) { -->
<!--           transitions[[hyp_num, end_num]] <- 0 -->
<!--         } else { -->
<!--           transitions[[hyp_num, end_num]] <- ( -->
<!--             init_transitions[[hyp_num, end_num]] + -->
<!--               init_transitions[[hyp_num, del_index]] * -->
<!--                 init_transitions[[del_index, end_num]] -->
<!--           ) / denominator -->
<!--         } -->
<!--       } -->
<!--     } -->
<!--     smaller_graph <- structure( -->
<!--       list( -->
<!--         hypotheses = hypotheses[-del_index], -->
<!--         transitions = as.matrix(transitions[-del_index, -del_index]) -->
<!--       ), -->
<!--       class = "initial_graph" -->
<!--     ) -->
<!--     children[[del_index]] <- delete_nodes_recursive( -->
<!--       smaller_graph, -->
<!--       orig_hyp_num -->
<!--     ) -->
<!--   } -->
<!--   c( -->
<!--     unlist(children, recursive = FALSE), -->
<!--     list(graph) -->
<!--   ) -->
<!-- } -->
<!-- ``` -->
<!-- ```{r ggw-recursive, echo=TRUE} -->
<!-- ggw_recursive <- function(graph) { -->
<!--   # The recursion requires the hypotheses to be named sequentially as actual -->
<!--   # numbers for the memory property to work -->
<!--   hyp_names <- names(graph$hypotheses) -->
<!--   names(graph$hypotheses) <- seq_along(graph$hypotheses) -->
<!--   colnames(graph$transitions) <- names(graph$hypotheses) -->
<!--   rownames(graph$transitions) <- names(graph$hypotheses) -->
<!--   # Recursively generate a list of all sub-graphs -->
<!--   list_subgraphs <- delete_nodes_recursive(graph) -->
<!--   # Process the list of graphs into the normal matrix form -->
<!--   matrix_weights <- structure( -->
<!--     do.call( -->
<!--       rbind, -->
<!--       lapply( -->
<!--         list_subgraphs, -->
<!--         function(graph) graph$hypotheses[as.character(seq_along(hyp_names))] -->
<!--       ) -->
<!--     ), -->
<!--     dimnames = list(1:(2^length(hyp_names) - 1), hyp_names) -->
<!--   ) -->
<!--   matrix_intersections <- !is.na(matrix_weights) -->
<!--   matrix_weights[is.na(matrix_weights)] <- 0 -->
<!--   cbind(matrix_intersections, matrix_weights) -->
<!-- } -->
<!-- ``` -->
<!-- ### Formula shortcut -->
<!-- Finally, the fastest method found so far - the formula shortcut. While recursion can save a lot of time over the first method, it still has a bit of overhead to get from the list of sub-graphs to the matrix form that is standard. This is where the "repeating block" property of the closure mentioned earlier is useful. Instead of using recursion to connect parent sub-graphs to their children, a pair of formulas can be used. One formula generates the parent of each graph that is obtained by flipping the left-most 0 to be a 1: `do.call(c, lapply(2^(seq_len(num_hyps) - 1), seq_len))`. Note that this is for rows 2 through the (non-existent) row 16, which is the empty graph. Row 1 has no parent graph. The left-most 0 in a child graph is easy to find, but from the parent graph's perspective, this formula calculates which hypothesis to delete: `rep(rev(seq_len(num_hyps)), 2^(seq_len(num_hyps) - 1))`. This also applies to rows 2 through 16. -->
<!-- ```{r parent-child-delete} -->
<!-- num_hyps <- length(ss_graph$hypotheses) -->
<!-- parents <- do.call(c, lapply(2^(seq_len(num_hyps) - 1), seq_len)) -->
<!-- parents <- c(NA, parents[-(2^num_hyps - 1)]) -->
<!-- delete <- rep(rev(seq_len(num_hyps)), 2^(seq_len(num_hyps) - 1)) -->
<!-- delete <- c(NA, delete[-(2^num_hyps - 1)]) -->
<!-- parent_child_demo <- cbind( -->
<!--   data.frame(Intersection = seq_len(2^num_hyps - 1)), -->
<!--   weighting_strategy[, seq_len(num_hyps)], -->
<!--   delete = delete, -->
<!--   parents = parents -->
<!-- ) -->
<!-- gt(parent_child_demo) |> -->
<!--   tab_header("Parent-child connections") |> -->
<!--   tab_spanner("To reach a given row...", delete:parents) |> -->
<!--   tab_style( -->
<!--     cell_text(align = "center", style = "italic"), -->
<!--     cells_body(Intersection) -->
<!--   ) |> -->
<!--   tab_style( -->
<!--     cell_text(align = "center"), -->
<!--     cells_body(c(delete, parents)) -->
<!--   ) |> -->
<!--   cols_label( -->
<!--     delete = "Delete hypothesis no.", -->
<!--     parents = "From intersection no." -->
<!--   ) -->
<!-- ``` -->
<!-- The formula shortcut also results in simpler code than the recursive solution. -->
<!-- ## Performance gains -->
<!-- ### Generating the closure -->
<!-- The formula method reduces each step of generating the closure to a single deletion from a prior graph, with almost no additional overhead. Here's how the different methods fare, including the version from the gMCP package for reference. Also worthy of note is the lrstat package, which contains a few MCP-related functions, including generating weights of the closure. It uses excellent C++ code to perform even faster, but since the speed of the current formula-based method is acceptable, adding an Rcpp dependency was not considered to be worth the additional time savings. -->
<!-- ```{r gw-benchmarks, eval=FALSE} -->
<!-- vec_num_hyps <- 2:8 * 2 -->
<!-- if (file.exists(here::here("vignettes/cache/gw_benchmark_list.rds"))) { -->
<!--   benchmarks <- read.csv(here::here("vignettes/cache/gw_benchmarks.csv")) -->
<!-- } else { -->
<!--   benchmark_list <- lapply( -->
<!--     vec_num_hyps, -->
<!--     function(num_hyps) { -->
<!--       cat(num_hyps, "\n") -->
<!--       # A graph for the Holm procedure -->
<!--       transitions <- matrix(1 / (num_hyps - 1), num_hyps, num_hyps) -->
<!--       diag(transitions) <- 0 -->
<!--       graph <- graph_create(rep(1 / num_hyps, num_hyps), transitions) -->
<!--       # lrstat sometimes errors, even when hypotheses seem to sum to 1. This -->
<!--       # fixes some of those cases -->
<!--       graph$hypotheses <- c( -->
<!--         graph$hypotheses[seq_len(num_hyps - 1)], -->
<!--         1 - sum(graph$hypotheses[seq_len(num_hyps - 1)]) -->
<!--       ) -->
<!--       benchmark <- mark( -->
<!--         gMCP = generateWeights(graph$transitions, graph$hypotheses), -->
<!--         `graphicalMCP simple` = ggw_simple(graph), -->
<!--         `graphicalMCP recursive` = ggw_recursive(graph), -->
<!--         `graphicalMCP shortcut` = graph_generate_weights(graph), -->
<!--         # lrstat still errors with graphs occasionally for unknown reasons -->
<!--         lrstat = if (!num_hyps %in% c(10, 14)) { -->
<!--           fwgtmat(graph$hypotheses, graph$transitions) -->
<!--         }, -->
<!--         check = FALSE, -->
<!--         memory = FALSE, -->
<!--         time_unit = "ms", -->
<!--         min_iterations = 5 -->
<!--       )[, 1:5] -->
<!--       # Remove rows for lrstat that weren't actually run -->
<!--       benchmark <- benchmark[benchmark$median > .002, ] -->
<!--       benchmark$char_expression <- as.character(benchmark$expression) -->
<!--       benchmark <- benchmark[, c("char_expression", "median")] -->
<!--       cbind(data.frame(num_hyps = num_hyps), benchmark) -->
<!--     } -->
<!--   ) -->
<!--   benchmarks <- do.call(rbind, benchmark_list) -->
<!--   benchmarks$char_expression <- ordered( -->
<!--     benchmarks$char_expression, -->
<!--     c( -->
<!--       "gMCP", -->
<!--       "graphicalMCP simple", -->
<!--       "graphicalMCP recursive", -->
<!--       "graphicalMCP shortcut", -->
<!--       "lrstat" -->
<!--     ) -->
<!--   ) -->
<!--   write.csv( -->
<!--     benchmarks, -->
<!--     here::here("vignettes/cache/gw_benchmarks.csv"), -->
<!--     row.names = FALSE -->
<!--   ) -->
<!--   # saveRDS(benchmark_list, here::here("vignettes/cache/gw_benchmark_list.rds")) -->
<!-- } -->
<!-- ``` -->
<!-- ```{r plot-gw-benchmarks, eval=FALSE, fig.dim=c(8, 5)} -->
<!-- benchmarks_plot_standard <- -->
<!--   ggplot(benchmarks, aes(num_hyps, median, color = char_expression)) + -->
<!--   geom_point() + -->
<!--   geom_line() + -->
<!--   theme_minimal() + -->
<!--   scale_y_continuous(labels = scales::label_comma(suffix = "ms")) + -->
<!--   scale_color_discrete() + -->
<!--   labs( -->
<!--     title = "Generating the weights of the closure", -->
<!--     subtitle = "Median runtime", -->
<!--     x = "Number of hypotheses", -->
<!--     y = NULL, -->
<!--     color = "Package" -->
<!--   ) -->
<!-- benchmarks_plot_standard + -->
<!--   scale_y_log10(labels = scales::label_comma(suffix = "ms")) + -->
<!--   labs(subtitle = "Log-10 median runtime") -->
<!-- ``` -->
<!-- ![](img/gw-benchmarks-plot.png) -->
<!-- ### Power simulations -->
<!-- While the time savings on the closure are nice, on most graphs the savings will not make a big difference compared to the longer run-times on e.g. power simulations. However, paying attention to the closure is important for other reasons too, such as improving the power algorithm. -->
<!-- #### Standard algorithm -->
<!-- The typical method for running a Bonferroni shortcut procedure on a graph is to: -->
<!-- 1.  Search a graph for a single hypothesis which can be rejected -->
<!-- 2.  Delete the rejected hypothesis and update weights -->
<!-- 3.  Repeat until there are no more significant hypotheses -->
<!-- Running this process in either R or a low-level language like C is fast for a single procedure, but when it's run 100,000 times for a power simulation, the R version becomes onerous. However, there's a lot of duplication in a power simulation using this method. In many of the simulations, the same steps will be taken, which means re-calculating the same set of weights many times. -->
<!-- #### Closure shortcut -->
<!-- The [binary counting](#binary-counting) property of the closure admits a shortcut which can be implemented in R to get a scalable competitor to the typical algorithm: -->
<!-- 1.  Generate the closure a single time to get all sub-graph weights efficiently -->
<!-- 2.  For each simulation: 1. Search a graph for all hypotheses which can be rejected - This is fast with vectorization 1. Using the binary counting property, index into the row of the closure corresponding to all hypotheses rejected so far to get updated weights - This is substantially faster than updating a graph and re-calculating weights, especially for larger graphs 1. Repeat using the updated weights -->
<!-- While this method is not as fast as gMCP's C implementation, it still runs substantial power simulations in a matter of seconds. The biggest drawback is how it can scale differently for different graph structures. For instance a fixed sequence procedure can take longer than a more balanced graph, like a Holm procedure, because it takes more steps to reject all possible hypotheses. -->
<pre><code><span><span class="co">#&gt; Scale for <span style="color: #00BB00;">y</span> is already present.</span></span>
<span><span class="co">#&gt; Adding another scale for <span style="color: #00BB00;">y</span>, which will replace the existing scale.</span></span></code></pre>
<p><img src="generate-closure_files/figure-html/plot-power-benchmarks-holm-1.png" width="768" style="display: block; margin: auto;"></p>
<!-- Fixed sequence -->
<pre><code><span><span class="co">#&gt; Scale for <span style="color: #00BB00;">y</span> is already present.</span></span>
<span><span class="co">#&gt; Adding another scale for <span style="color: #00BB00;">y</span>, which will replace the existing scale.</span></span></code></pre>
<p><img src="generate-closure_files/figure-html/plot-power-benchmarks-fs-1.png" width="768" style="display: block; margin: auto;"></p>
<!-- ![](img/power-benchmarks-plot.png) -->
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Dong Xi, Ethan Brockmann, Gilead Biostatistics.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
